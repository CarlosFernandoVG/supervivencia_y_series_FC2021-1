--- 
title: "Modelos de Supervivencia"
author:
  - "Sofía Villers Gómez"
  - "Carlos Fernando Vásquez Guerra"
  - "Luis Angel Ramirez Teodoro"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
geometry: "top=1in, left=1in, right=1in, bottom=1in"
classoption: [a4paper, oneside, openany]
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
css: styles.css
github-repo: CarlosFernandoVG/supervivencia_y_series_FC2021-1
url: 'https\://github.com/CarlosFernandoVG/supervivencia_y_series_FC2021-1'
description: "Material para el curso Análisis de Supervivencia y Series de Tiempo 2021-1 en la Facultado de Ciencias, Universidad Nacional Autónoma de México"
always_allow_html: true
---

# Prefacio {-}

```{r include = FALSE}
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
library(tidyverse)
library(devtools)
source("functions.R")
library(patchwork)
library(latex2exp)
library(shape)
library(futurevisions)
library("actuar")
library(knitr)
library(kableExtra)
library(survival)
knitr::opts_chunk$set(
      comment = NA,
      message = FALSE, 
      warning = FALSE,
      echo = FALSE,
      fig.align = "center",
      fig.height = 4
)
```

Primera edición del bookdown  _Modelos de Supervivencia_ para su uso en la materia Análisis de Supervivencia y Series de tiempo y sus relacionadas impartidas por los autores, así como para aquellos estudiantes que deseen adquirir el conocimiento pertinente de tal tópico.

### Objetivos {-}

+ Otorgar un material electrónico de calidad con el contenido referente al Análisis de Supervivencia como un esfuerzo de los autores para lograr un proceso de aprendizaje autodidacta por parte del alumno y así optimizar el tiempo, tanto de los profesores, como el de los alumnos.

+ Plasmar las bases teóricas de esta rama de la estadística con el uso de ejemplos y contenido visual para un mejor entendimiento de cada subtema que se trate.

### Estructura {-}

Este libro se compone de diez diferentes capítulos comenzando con los tipos de datos con el que se puede encontrar el lector en un estudio de supervivencia, dado esto, en el capítulo 3 se comienza con el estudio de las distintas funciones de supervivencia, así como las funciones que se deriven de esta, para los casos discreto y continuo. En el capítulo 4 se desglosa la teoría correspondiente a la obtención de parámetros poblacionales, como lo son la media y la varianza; para así en el capítulo 5 tratar modelos paramétricos comunes donde se asume una distribución para los datos a tratar y se obtienen las funciones vistas en los capítulos previos. El capítulo 6 abarca lo correspondiente a la obtención de la función de verosimilitud en datos censurados y truncados. Respecto a los capítulos 7 y 8 se da la teoría, junto a varios ejemplos, para el análisis no paramétrico en un análisis de supervivencia para que en el capítulo 9 se establezcan las pruebas de hipótesis pertinentes. Finalmente en el capítulo 10 se considera el modelo de riesgos proporcionales y se estudian las implicaciones sobre algunos tópicos de los capítulos anteriores.

Se recomienda que la consulta de los capítulos se realice de acuerdo al índice, ya que a medida que se avanza en índice, se asume el conocimiento de los capítulos previos.

### Detalles técnicos {-}

Para la creación de este material se hizo uso de varios sistemas de software como LaTeX y CSS para el diseño de ciertos elementos. Todos los cálculos y gráficas fue creado con el lenguaje de programación `R` ya sea con el uso del paquete `base` o algún otro de los paquetes que se mencionan a continuación. 

```{css, echo=FALSE}
.scroll-300 {
  max-height: 300px;
}
```

```{r message = FALSE, warning = FALSE, echo = FALSE, class.output = "scroll-300"}
sessionInfo()
```

Este libro fue escrito con [bookdown](http://bookdown.org/) usando [RStudio](http://www.rstudio.com/ide/).

Esta versión fue escrita con:

```{r message = FALSE, warning = FALSE, echo = FALSE}
# needed because new_session is set to true in _bookdown.yml
all_pkgs <- renv::dependencies(path = "DESCRIPTION") %>% 
  pull(Package) 
session <- devtools::session_info(pkgs = all_pkgs)
session$platform
```

### Licencia {-}

This work is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).

<center>
<i class="fab fa-creative-commons fa-2x"></i><i class="fab fa-creative-commons-by fa-2x"></i><i class="fab fa-creative-commons-sa fa-2x"></i>
</center>

*This is a human-readable summary of (and not a substitute for) the license.
Please see <https://creativecommons.org/licenses/by-sa/4.0/legalcode> for the full legal text.*

**You are free to:**

- **Share**---copy and redistribute the material in any medium or
  format

- **Remix**---remix, transform, and build upon the material for any
  purpose, even commercially.

The licensor cannot revoke these freedoms as long as you follow the
license terms.

**Under the following terms:**

- **Attribution**---You must give appropriate credit, provide a link
  to the license, and indicate if changes were made. You may do so in
  any reasonable manner, but not in any way that suggests the licensor
  endorses you or your use.
  
- **ShareAlike**---If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original. 

- **No additional restrictions**---You may not apply legal terms or
  technological measures that legally restrict others from doing
  anything the license permits.

**Notices:**

You do not have to comply with the license for elements of the
material in the public domain or where your use is permitted by an
applicable exception or limitation.

No warranties are given. The license may not give you all of the
permissions necessary for your intended use. For example, other rights
such as publicity, privacy, or moral rights may limit how you use the
material.

```{r include = FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown', 'ggplot2'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

# (PART) Todo es cuestion de tiempo {-}

# Motivación {-}

En los dos cursos anteriores de estadística se ha trabajado con datos (muestras aleatorias) exactos, es decir, datos que se conocen en su totalidad y que, con base en ellos, hemos realizado estimaciones sobre los parámetros poblacionales. Sin embargo, puede suceder que los datos se conozcan parcialmente, o bien, se desconozcan; esto suele suceder en estudios que tienen limitados recursos y tiempo para llevarse a cabo, por ejemplo: estudios sobre la efectividad de un tratamiento clínico, la reaparición de cierta enfermedad en pacientes, confiabilidad industrial, etcétera.

Lo anterior sugiere plantearnos algunas preguntas interesantes: *¿Cómo realizamos estimaciones con datos parciales?, ¿Se puede ajustar algún modelo paramétrico con datos parciales?, ¿Podemos comparar poblaciones con datos parciales?*. Éstas y otras cuestiones abordaremos a lo largo del curso de *Modelos de Supervivencia y Series de Tiempo*. En general, en la primer parte del curso (Análisis de supervivencia) se establecerán las bases teóricas para el tratamiento de datos parciales en modelos conocidos (paramétricos), y además estudiaremos modelos No paramétricos para este tipo de datos.

Por otro lado, responder preguntas como: *¿Cuál será el precio de las acciones de Facebook para el último bimestre del 2020?, ¿Cuál será el nivel de partículas contaminantes en la CDMX para noviembre de 2020?, ¿Cuál será la capacidad de un procesador intel para el año 2021?*, puede parecer, en primera instancia, una tarea complicada. Si bien no tenemos una "bola mágica" con la que podamos adivinar el futuro, disponemos de ciertos procesos estocásticos llamados *Series de Tiempo*, cuyo objetivo principal es el *pronóstico*; estos se abordarán en la segunda parte del curso, y por ende en un próximo bookdown.

# Análisis de Supervivencia {-}

El análisis de supervivencia se basa en el estudio del __tiempo__, en la ocurrencia de un __evento__. El término supervivencia se debe a que en las primeras aplicaciones de este método de análisis se utilizaba como __evento__ la muerte de un paciente; tradicionalmente el análisis de supervivencia se ha asociado al análisis de datos en ensayos médicos.

El __tiempo de superviviencia o falla__ se define como el tiempo transcurrido desde el estado inicial hasta la ocurrencia de un evento dado. Por ejemplo, en un estudio que consiste en observar la remisión de cierta enfermedad en pacientes, se puede definir el tiempo de falla como el tiempo en el que tarda en reaparecer la enfermedad en los pacientes. Otros ejemplos de tiempo de falla son: los tiempos que toman los individuos para completar tareas específicas en experimentación psicológica, tiempos en los que tardan ciertas máquinas industriales en descomponerse, la longitud de trayectorias sobre una placa fotográfica en física de partículas.

Para determinar el tiempo de falla de forma precisa, hay tres requerimientos: un tiempo de origen que debe ser definido, una escala para medir el paso del tiempo que debe ser congruente al problema y finalmente, el significado de falla que debe ser completamente claro. Frecuentemente la escala para medir el paso de tiempo es el tiempo reloj (tiempo real), sin embargo hay otras posibilidades, como el kilometraje en un auto o el uso operacional de un sistema. Evidentemente, se pide que los tiempos de falla sean __No negativos__.

Resulta de interés conocer (si es posible) la distribución de los tiempos de falla. En general los estudios que hemos ejemplificado anteriormente tienen limitaciones para llevarse a cabo, en consecuencia se establece algún periodo fijo de observación; es en este punto en el que pueden surgir *datos  parcialmente conocidos*.

A continuación se muestra con ejemplos algunas de las diferentes formas como se pueden presentar los datos de supervivencia. Todos los ejemplos tienen un tiempo de origen, una escala de medición y una definición de falla.

1. Datos de supervivencia de pacientes psiquiatricos.

```{r}
data_frame("Género" = c("Femenino","Femenino", "Femenino", "Masculino", "Femenino", "Masculino", "Masculino"), "Edad de admisión" = c(51, 58, 55, 21, 25, 19, 24), "Tiempo de seguimiento" = c("1", "1", "2", "$30^+$", 32, 28, "$33^+$")) %>% 
  kable(booktabs = T, align=rep('c'), escape = FALSE) %>% 
  kable_styling(bootstrap_options = "striped", full_width = F) %>% 
  column_spec(1:2, border_right = T)
```

En esta forma de presentar los datos $^+$ significa que la observación es censurada, es decir no se observo más allá de los 30 o 33 años. Las observaciones censuradas se verán en la siguiente sección.

2. Tiempos de infección (en meses) de pacientes en diálisis con diferentes procedimientos de cateterización.

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-style:solid;border-width:0px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;
  padding:10px 5px;word-break:normal;}
.tg th{border-style:solid;border-width:0px;font-family:Arial, sans-serif;font-size:16px;font-weight:normal;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-c3ow" colspan="4">Colocación de catéter de forma quirúrgica</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0pky" colspan="4">Tiempos de Infección: 1.5,3.5,4.5,4.5,5.5,8.5,8.5,9.5,10.5,11.5,15.5,16.5,18.5,23.5,26.5</td>
  </tr>
  <tr>
    <td class="tg-0pky" colspan="4">Observaciones Censuradas:2.5,2.5,3.5,3.5,3.5,4.5,5.5,6.5,6.5,7.5,7.5,7.5,7.5,8.5,9.5</td>
  </tr>
</tbody>
</table>

<table class="tg">
<thead>
  <tr>
    <th class="tg-c3ow" colspan="4">Colocación de catéter de forma percutánea</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0pky" colspan="4">Tiempos de Infección: 0.5,0.5,0.5,0.5,0.5,0.5,2.5,2.5,3.5,6.5,15.5</td>
  </tr>
  <tr>
    <td class="tg-0pky" colspan="4">Observaciones Censuradas:0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,1.5,1.5,1.5,1.5,2.5</td>
  </tr>
</tbody>
</table>


3. Consumo de la marihuana en la preparatoria

```{r}
data_frame(Edad = c(10, 11, 12, 13, 14), "Total de observaciones" = c(4, 12, 19, 24, 20), 
           "Aún no la han probado" = c(0, 0, 2, 15, 24), 
           "Empezaron a fumar a edad más temprana" = c(0, 0, 0, 1, 2)) %>%
  kable(booktabs = T, align=rep('c'), escape = FALSE) %>% 
  kable_styling(bootstrap_options = "striped", full_width = F) %>% 
  column_spec(1:3, border_right = T)
```

Los ejemplos anteriores son extracciones de ejemplos en el libro [@klein2006survival].

<!--chapter:end:01_Introduction.Rmd-->

# Datos Censurados

Ocurren cuando el tiempo de falla se conoce sólo en cierto periodo de tiempo. Por ejemplo, un estudio consiste en observar la muerte (tiempo de falla) de pacientes en un periodo establecido, algunos de ellos pueden estar vivos todavía al final del periodo de estudio. Los tiempos de supervivencia exactos de estos sujetos son desconocidos, pero tenemos información parcial. Estas son llamadas **observaciones censuradas**, y se denotan por $+$.

## Censura por la Derecha Tipo I

Nos referimos a este tipo de censura cuando el estudio se termina a un tiempo fijo predeterminado (tiempo de censura) independientemente del tamaño de la muestra (número total de individuos en el estudio). 

#### Ejemplo {-}

Un investigador de la facultad de ciencias realiza un estudio en  5 ratas de laboratorio y ha determinado que la duración de este será de un año y medirá el tiempo (en meses) en que cada rata fallece . Al cabo del año se obtuvieron los siguientes resultados: $3,4,8,10,12^+$, esto quiere decir que una rata murió a los tres meses iniciado el estudio, otra lo hizo en 4 meses, etcétera; la quinta rata permaneció con vida hasta el final del estudio, es decir, no presentó la falla en el tiempo predeterminado de observación por lo tanto es un dato censurado.

```{r}
survival_study_graph(t_fallo = c(3,4,8,10,12), censura = c(0,0,0,0,1))+
  labs(x = "Meses", y = "Ratas")+
  lims(y = c(1, 5.5))+
  geom_vline(xintercept = 12,  linetype="dashed")+
  annotate("segment", x = 12, xend=13, y = 5, yend =5)+
  scale_y_continuous(expand = expand_scale(mult = c(0.05, 0.05)))+
  scale_x_continuous(breaks = seq(0,12,2) , labels = seq(0,12,2),
                     expand = expand_scale(mult = c(.05, 0)))
```

## Censura por la Derecha Tipo II

Ocurre cuando el estudio continua hasta que se presenta la falla de los primeros $r<n$ individuos. Donde $r$ es el número de individuos predeterminado a observar y $n$ es el número total de individuos en el estudio. En este tipo de censura hay dependencia del tamaño de muestra y de las fallas que se observen.

#### Ejemplo {-}

Las limitaciones económicas para la investigación científica han hecho que un especialista en cancerología tome la decisión de observar los tiempos (en días) de sólo 5 conejos hasta que desarrollen un tumor, de un total de 9. Al final se obtuvo lo siguiente: $30,34,43,45,60,60^+,60^+,60^+,60^+$, ¿Cómo interpretaría usted los resultados obtenidos por el especialista? 

```{r}
tiempo_conejos <- c(30,34,43,45,60,60,60,60,60)
censura <- c(0,0,0,0,0,1,1,1,1)
survival_study_graph(t_fallo = tiempo_conejos, censura = censura)+
  labs(x = "Días", y = "Conejos")+
  scale_y_continuous(breaks = 1:9, labels = 1:9)+
  annotate("segment", y = c(6,8,9), yend = c(6,8,9), x = 60,xend = 63)+
  scale_x_continuous(expand = expand_scale(mult = c(.05, 0)))
```

## Censura por la Derecha Tipo III

Llamada también censura aleatoria. Se denomina así porque el tiempo de censura lo determina un fenómeno aleatorio, que tiene lugar durante la consecución del estudio e impide seguir con la observación del individuo hasta el tiempo final; es decir que $T_i$ es una variable aleatoria. En general, la censura aleatoria surge cuando los individuos salen del estudio sin presentar la falla por razones __no__ controladas por el investigador. Cuando sucede tal censura, se dice que se tiene una _análisis de riesgos competitivos_.

Finalmente, si el mecanismo de censura aleatoria es _dependiente_ de los tiempos de falla, se dice que este es una _censura informativa_, ya que otorga información a los tiempos de falla; en caso contrario es _no informativa_.

#### Ejemplo {-}

Algunos ejemplos son la migración a otra ciudad o los casos donde el paciente se retira del estudio o muere por alguna causa ajena al evento de interés. La siguiente gráfica muestra un ejemplo de datos con censura aleatoria.

```{r}
survival_study_graph(inicio = c(0,1,3,4,6,14), t_fallo = c(10,12,16,29,32,30),
                     censura = c(0,1,0,0,0,1))+
  labs(x = "Días", y = "Conejos")+
  scale_y_continuous(breaks = 1:6, labels = 1:6)
```

## Censura por la Izquierda

Las observaciones censuradas por la izquierda serán aquellas en las que el evento de interés ha tenido lugar antes del punto de inicio del estudio. Así, el tiempo de censura en este caso será el tiempo de inicio del estudio.

#### Ejemplo {-}

Un ejemplo de este tipo de censura son los tiempos al primer uso de marihuana. Como se observa en el ejemplo en la introducción de este capítulo, el levantamiento de la información se hace sobre alumnos de preparatoria y hay casos en los que el inicio del consumo es a una edad previa al levantamiento de los datos. Entonces aquellos jóvenes cuyo primer uso de marihuana es a una edad previa a la registrada en ese momento, serán consideradas como observaciones censuradas por la izquierda.

Frecuentemente si un estudio tiene censura por la izquierda, entonces se tendrá doble censura, por lo que se denota como $C_i$ al tiempo antes del cual algunos individuos presentan el evento de interés y $C_d$ al tiempo después del cual algunos de los individuos presentan el evento de interés.

## Censura por Intervalos

Ocurre cuando los individuos en el estudio son monitoreados intermitentemente en momentos discretos de tiempo, de modo que, es posible que el suceso de estudio haya tenido lugar en un tiempo entre dos de las mediciones.

Si el individuo $i$ no ha presentado el evento de interés al fin del tiempo $I_i$ pero a la siguiente observación $D_i$ sí presentó el evento, entonces es una falla censurada en el intervalo $(I_i,D_i)$.

#### Ejemplo {-}

Un investigador lleva a cabo un estudio en ratas diseñado para evaluar los efectos de dietas ricas en vegetales en el riesgo de cáncer de mama. El tumor mamario es inducido con una única dosis de DMBA al inicio del estudio. 6 semanas después de la administración del DMBA, cada rata es examinada una vez a la semana por 14 semanas y el tiempo en que el tumor es palpable es registrado. Si una rata presenta tumor en la quinta revisión, entonces lo que se sabe es que el tumor en la cuarta revisión no era palpable y por lo tanto este debió presentarse entre la cuarta y quinta revisión dando como resultado que esa observación esta censurada en el intervalo (semana 10, semana 11). 

# Datos Truncados

El truncamiento tiene lugar cuando sólo aquellos sujetos que manifiestan el evento dentro de una ventana observacional $(U,V)$ son observados, del resto no se realiza ningún seguimiento y, por tanto, no se obtiene información sobre ellos (no hay información parcial). Las observaciones $t_i$ tales que $t_i<U$, serán observaciones truncadas por la izquierda y aquellas que $t_i>V$ serán observaciones truncadas por la derecha.

#### Ejemplos de Datos Truncados {-}

Deseamos medir la supervivencia de adultos mayores de 60 años. Entonces necesitamos que los individuos tengan al menos 60 años para que sean considerados en el estudio, por lo que el estudio está truncado por la izquierda. Otro ejemplo es si deseáramos medir la distancia de la tierra a las estrellas, este sería truncado por la derecha ya que no se puede ver más allá de un límite.

Es importante mencionar que la diferencia entre *truncamiento* y *censura* es la información parcial disponible. En datos censurados hay información parcial, mientras que en datos truncados no.

#### Ejemplos del caso continuo y caso discreto {-}

Un número grande de individuos sanos fueron enrolados en un estudio que inicio el 1/01/1970. Los individuos fueron seguidos por 30 años para estudiar la edad a la que desarrollaron cáncer de mama. Fueron sometidos a exámenes clínicos cada 3 años. Menciona si hay censura o truncamiento en:

1. Individuo sano, enrolado a los 30 años, durante el periodo de estudio nunca desarrollo cáncer de mama.
2. Individuo sano, enrolado en el estudio con 40 años de edad, se le diagnosticó cáncer de mama en el quinto examen clínico.
3. Individuo sano, enrolado con 50 años de edad, murió a los 63 años por paro cardíaco.
4. Individuo con cáncer de piel en remisión.

<!--chapter:end:02_Censored.Rmd-->

# (PART) Estudio paramétrico {-}

# Funciones para el Análisis de Supervivencia

Dado que el análisis de supervivencia se basa en tiempos de falla, definiremos a continuación funciones importantes que se pueden asociar a estos. Evidentemente, estamos pensando que los tiempos de falla provienen de una variable aleatoria **No negativa**[^3.3] $T$ la cual llamaremos *variable aleatoria del tiempo de falla*, equivalentemente *longitud de tiempo de vida futura* o *tiempo de superviviencia*. Por simplicidad la llamaremos *tiempo de supervivencia*.

$T$ es usualmente descrita o caracterizada por cuatro funciones:

+ *1.- Función de supervivencia*
+ *2.- Función de densidad de probabilidad*
+ *3.- Función de riesgo*
+ *4.- Función de riesgo acumulado*

Estas funciones son matemáticamente equivalentes; a partir de una se derivan las otras tres. Cabe destacar que, dependiendo el caso, $T$ puede ser una variable aleatoria continua o bien, discreta.

## Función de Supervivencia

### Caso continuo {-}

La función de supervivencia $S(t)$, tanto en el caso continuo como en el discreto, se define como la probabilidad de que un individuo sobreviva más allá del tiempo $t$. Para el caso continuo:

$$
S(t)=\mathbb{P}(T>t)=1-F_T(t)=\int_{t}^{\infty}f_T(u)du
$$

Si tomamos la igualdad $S(t)=1-F_T(t)$ y derivamos en ambos lados y multiplicamos por $-1$, obtenemos:

$$
-\frac{d}{dt}S(t)=f_T(t)
$$

Las propiedades de $S(t)$ son:

1.-Es monótona no creciente.

2.- $S(t)=1$ para $t=0$.

3.- $S(t)=0$ cuando $t\rightarrow\infty$.

La función $S(t)$ es conocida también como la *tasa de superviviencia acumulativa*; en el contexto industrial se conoce como *función de confiabilidad*. 

Por otro lado, es de suma importancia representar $S(t)$ gráficamente ya que de ella se puede obtener información interesante; por ejemplo el cálculo de diversos cuantiles (como el cuantil 50) nos permitirán hacer inferencias y comparar distribuciones de superviviencia de dos o más grupos de individuos. La gráfica de $S(t)$ es llamada **curva de supervivencia**, los gráficos de la figura \@ref(fig:two-example-survival-functions) son ejemplos de esta.

```{r two-example-survival-functions, fig.cap='Ejemplos de la curva de supervivencia.'}
#grafico de supervivencia baja
survival_example_1 <- tibble(x = c(0,30)) %>% 
  ggplot(aes(x = x))+
  stat_function(fun = ~1-pexp(.x,rate=.8))+
  general_theme+
  labs(x = "Tiempo", y = TeX("$S(t)$"))+
  ggtitle("Tratamiento 1")
#grafico de supervivencia alta
survival_example_2 <- tibble(x = c(0,30)) %>% 
  ggplot(aes(x = x))+
  stat_function(fun = ~1-pexp(.x,rate=.1))+
  general_theme+
  labs(x = "Tiempo", y = TeX("$S(t)$"))+
  ggtitle("Tratamiento 2")
survival_example_1+survival_example_2
```

En la primer gráfica se observa una tasa de supervivencia baja, mientras que en la segunda gráfica se tiene una tasa alta. En este contexto, ¿qué podríamos decir de los pacientes con el tratamiento 1 *versus* los pacientes con el tratamiento 2?

### Caso discreto {-}

Si $T$ es una variable aleatoria discreta  que toma valores $0<t_1<t_2<...$ Entonces la función de probabilidad de $T$ es:

$$
f(t) = \left\{
\begin{array}{ll}
\mathbb{P}(T=t_j) & \mbox{ si  } t=t_j, j=1,2,...\\
0 & \mbox{en otro caso }
\end{array}
\right.
$$

Por lo que su función de supervivencia es:

$$
S(t)=\mathbb{P}(T> t)=\sum_{t< t_j}f(t_j)
$$
La siguiente es una representación gráfica de la función de supervivencia en el caso discreto

```{r}
tibble(x = c(0,1,5,6), x_end = c(1,2,6,7),  y = c(3.5, 3, 1, .5) ) %>%
  ggplot(aes(x = x, y = y))+
  geom_segment(aes(x = x, xend = x_end, y = y, yend  = y))+
  annotate("point", x = c(1, 2, 6, 7), y = c(3.5, 3, 1, .5),
           shape = 21, size = 3, color = "black", fill = "white")+
  annotate("point", x = c(1, 5, 6), y = c(3, 1, .5),
           shape = 19, size = 3, color = "black")+
  annotate("point", x = c(3, 3.5, 4), y = c(2, 1.75, 1.5), shape = 16, size = 2)+
  annotate("segment", x = 6.5, xend = 6.5, y = 0, yend = .75, linetype = "dashed")+
  annotate("text", x = 6.5, y = .9, label = TeX("$t_i$"), size = 4)+
  labs(x = NULL, y = TeX("$S(t)$"))+
  scale_y_continuous(limits = c(0,4), expand = expand_scale(mult = c(0, 0)))+
  scale_x_continuous(breaks = c(1, 2, 6, 7), expand = expand_scale(mult = c(0,0.1)),
                     labels = c(TeX("$u_1$"),TeX("$u_2$"), TeX("$u_{k-1}$"), TeX("$u_{k}$")))+
  theme(axis.line = element_line(arrow =arrow(type = "closed", 
                       length = unit(0.1, "inches"))),
        axis.text.y=element_blank(),
        axis.ticks.y = element_blank())+
  general_theme
```

Al igual que el caso continuo, se tienen las propiedades:

1.-Es monótona no creciente

2.- $S(t)=1$ para $t=0$.

3.- $S(t)=0$ cuando $t\rightarrow\infty$.

#### Ejemplos del caso continuo y caso discreto {-}

Estos pueden verse al final de la sección \@ref(par-poblacionales)

## Función de Riesgo {#RiskFunction}

### Caso continuo {-}

La función de riesgo $h(t)$ (hazard function), también llamada **tasa de falla condicional** (en el análisis de confiabilidad) o *tasa de mortalidad* (en demografía), se define como la probabilidad de falla durante un intervalo de tiempo muy pequeño suponiendo que el individuo ha sobrevivido hasta el inicio del intervalo[^3.1]; en expresiones matemáticas es:

$$
h(t)=\lim_{\alpha\rightarrow 0}\frac{1}{\alpha}\mathbb{P}(t<T\leq t+\alpha|T\geq t)
\\
=\lim_{\alpha\rightarrow 0}\frac{1}{\alpha}\frac{\mathbb{P}(T\leq t+\alpha)-\mathbb{P}(T<t)}{\mathbb{P}(T\geq t)}\\
=\lim_{\alpha\rightarrow 0}\frac{1}{\alpha}\frac{F(t+\alpha)-F(t)}{S(t)}
=\frac{f(t)}{S(t)}
$$

Entonces

$$
h(t)=\frac{f(t)}{S(t)}=\frac{f(t)}{1-F(t)}=-\frac{d}{dt}log(S(t))
$$

Si tomamos la igualdad 

$$
h(t)=-\frac{d}{dt}log(S(t))
$$

Y despejamos a $S(t)$ tenemos que:

$$
S(t)=exp\left[-\int_{0}^{t}h(u)du\right]=exp[-H(t)]
$$

Donde $H(t)=\int_{0}^{t}h(u)du$ es conocida como **la función acumulada de riesgo**, la cual veremos más adelante.

La función de riesgo juega un papel importante en el análisis de supervivencia. Describe la forma en que cambia la _tasa instantánea de muerte de un individuo al paso del tiempo_ (constante, lineal, exponencial, etc.). El conocer $h(t)$ puede darnos alguna idea sobre la selección del modelo para la distribución del tiempo de supervivencia, por ejemplo, puede ser útil al considerar restricciones para modelos con funciones de riesgo no decrecientes o modelos con funciones de riesgo no crecientes.

No hay un comportamiento "habitual" en la gráfica de $h(t)$, es decir, $h(t)$ puede crecer, decrecer, ser constante o  mostrar algo más complicado. El esquema siguiente muestra algunos ejemplos de la gráfica de $h(t)$:

```{r}
tibble(x = seq(0,4,0.1)) %>% 
  ggplot(aes(x = x)) +
  geom_line(aes(y = 1-pexp(x, rate = .5), colour = "1"))+
  geom_line(aes(y = rep(.6, length(x)), colour = "2"))+
  geom_line(aes(y = dnorm(x,1.5,1)+.35, colour = "3"))+
  geom_line(data = tibble(x_1= seq(0,4,0.1), x_brown = 0.02+x_1), 
            aes(x = x_brown, y = pnorm(x_1,1.5,1)+.3, colour = "4"))+
  geom_line(data = tibble(x_2 = seq(-1,2,0.1), x_blue_1 = 1.1+x_2),
            aes(x = x_blue_1, y = .15*x_2^2+.3, colour = "5"))+
  geom_line(data = tibble(x_3 = seq(-1.5,-1,0.1), x_blue_2 = 1.1+x_3),
            aes(x = x_blue_2, y = .5*x_3^2-.05), color = "deepskyblue1")+
  lims(y = c(0,1), x = c(-0.2, 4))+
  scale_x_continuous(expand = expand_scale(mult = c(-.021,0)))+
  general_theme+
  theme(legend.key = element_blank(),
        legend.background = element_blank(),
        legend.position = "bottom",
        legend.box.background = element_blank(),
        legend.direction = "horizontal",
        legend.spacing.x = unit(.2, 'cm'),
        axis.text.y=element_blank(),
        axis.ticks.y = element_blank())+
  scale_color_manual(values = c(futurevisions("hd")[1], "firebrick",
                                futurevisions("hd")[3:4],"deepskyblue1"),
                     labels = c("Decreciente", "Constante", "Montaña",
                                "Creciente", "Tina de baño"),
                     guide = guide_legend(label.position = "left",
                                          label.hjust = 0.5))+
  labs(x = NULL, y = TeX("$h(t)$"), colour = "Tipo de curva:")+
  ggtitle("Ejemplos de Funciones de Riesgo")
```

La curva $h(t)$ en color azul (*llamada curva de tina de baño*) describe el proceso de la vida humana: al inicio existe mortalidad infantil y el riesgo de morir es alto, crece el individuo y el riesgo de morir se reduce y hasta cierto punto es constante, después viene el envejecimiento(hay deterioro) y entonces el riesgo de morir aumenta. Una función de riesgo creciente como la curva de color verde implica un envejecimiento natural. Una función decreciente como la curva color morado es menos común e indica rejuvenecimiento. Una función en forma de montaña como la curva color café, podría representar un comportamiento de muerte por enfermedad después de llevar un tratamiento para la misma enfermedad.

### Caso discreto {-}

En este caso, la función de riesgo proporciona la probabilidad condicional de falla al tiempo $t=u_k$, dado que el individuo estaba vivo antes de $u_k$.

Sea $T$ una variable aleatoria discreta con soporte en $\{u_1,u_2,u_3,...\}$. La función de riesgo al tiempo $u_k$ se define como[^3.2]

$$
h(u_k)=\mathbb{P}(T=u_k|T\geq u_k)=\frac{\mathbb{P}(T=u_k)}{\mathbb{P}(T\geq u_k)} =\frac{f_T(u_k)}{S_T(u_{k-1})}
$$

Observemos que:

$$
f_T(u_k)=\mathbb{P}(T=u_k)=\mathbb{P}(T\geq u_k)-\mathbb{P}(T> u_{k})= S(u_{k-1})-S(u_{k})
$$

si dividimos entre $S(u_{k-1})$, tenemos entonces:

$$
h(u_k)=\frac{S(u_{k-1})-S(u_{k})}{S(u_{k-1})}=1-\frac{S(u_{k})}{S(u_{k-1})}
$$

Por otro lado, para $S(t)$ se cumple que:

$$
S(t)=\frac{S(t)}{1}=\frac{S(t)}{S(0)}=\frac{S(u_1)}{S(0)}.\frac{S(u_2)}{S(u_1)}.\frac{S(u_3)}{S(u_2)}...\frac{S(u_k)}{S(u_{k-1})}.\frac{S(t)}{S(u_k)}
$$

Entonces, de la expresión anterior y ocupando que $h(u_k)=1-\frac{S(u_{k})}{S(u_{k-1})}$ tenemos finalmente:

$$
S(t)=\prod_{k: u_k \leq t}\frac{S(u_k)}{S(u_{k-1})} =\prod_{k: u_k \leq t}(1-h(u_k))
$$

Si queremos obtener $f(u_k)$, la podemos conocer partir de la función de riesgo:

$$
f(u_k)=\frac{f(u_k)}{S(u_{k-1})}S(u_{k-1})=h(u_k)S(u_{k-1})=h(u_k) \prod_{j<k} \frac{S(u_j)}{S(u_{j-1})}=h(u_k) \prod_{j<k}(1-h(u_j))
$$

La expresión 

$$
S(t)=\prod_{k: u_k \leq t}(1-h(u_k))
$$

la ocuparemos más adelante.

#### Ejemplo {-}

Suponga que se tiene la siguiente distribución para la variable aleatoria $T$: $\mathbb{P}(T = j) = \frac{1}{3}; \ \ j = 1,2,3$

Para este caso se tienen los siguientes resultados junto con las siguientes representaciones gráficas:

$$
S(t) = \left\{
\begin{array}{ll}
1 & -\infty<t<1\\
\frac{2}{3} &  1\leq t<2\\
\frac{1}{3} & 2\leq t < 3\\
0 & t\geq 3
\end{array}
\right.
h(t) = \left\{
\begin{array}{ll}
\frac{f(1)}{S(0)} = \frac{1}{3} & t = 1\\
\frac{f(2)}{S(1)} = \frac{1}{2} & t = 2\\
\frac{f(3)}{S(2)} = 1 & t = 3
\end{array}
\right.
$$

```{r}
F_example_3 <- tibble(x = c(0,5)) %>% 
  ggplot(aes(x = x)) +
  annotate("segment", x = c(0,1,2,3), xend = c(1, 2, 3, 5), 
           y = c(0, 1/3, 2/3, 1), yend = c(0, 1/3, 2/3, 1)) +
  annotate("point", x = c(1, 2, 3), y = c(0, 1/3, 2/3),
           shape = 21, size = 3, color = "black", fill = "white") +
   annotate("point", x = c(1, 2, 3), y = c(1/3, 2/3, 1),
           shape = 19, size = 3, color = "black") + 
  theme(axis.line = element_line(arrow =arrow(type = "closed", 
                       length = unit(0.1, "inches")))) +
  scale_y_continuous(breaks = c(0, 1/3, 2/3, 1), 
                     labels = c(0, TeX("$\\frac{1}{3}$"), TeX("$\\frac{2}{3}$"), "1"), limits = c(-.1,1.7), 
                     expand = expand_scale(mult = c(0,0))) +
  scale_x_continuous(breaks = c(1, 2, 3), 
                     labels = c(1, 2, 3), 
                     expand = expand_scale(mult = c(0,0))) +
  labs(x = TeX("$t$"), y = TeX("$F(t)$")) + 
  general_theme
S_example_3 <- tibble(x = c(0,5)) %>% 
  ggplot(aes(x = x)) +
  annotate("segment", x = c(0,1,2,3), xend = c(1, 2, 3, 5), 
           y = 1-c(0, 1/3, 2/3, 1), yend = 1-c(0, 1/3, 2/3, 1)) +
  annotate("point", x = c(1, 2, 3), y = 1-c(0, 1/3, 2/3),
           shape = 21, size = 3, color = "black", fill = "white") +
   annotate("point", x = c(1, 2, 3), y = 1-c(1/3, 2/3, 1),
           shape = 19, size = 3, color = "black") + 
  theme(axis.line = element_line(arrow =arrow(type = "closed", 
                       length = unit(0.1, "inches")))) +
  scale_y_continuous(breaks = c(0, 1/3, 2/3, 1), 
                     labels = c(0, TeX("$\\frac{1}{3}$"), TeX("$\\frac{2}{3}$"), "1"), limits = c(-.1,1.7), 
                     expand = expand_scale(mult = c(0,0))) +
  scale_x_continuous(breaks = c(1, 2, 3), 
                     labels = c(1, 2, 3), 
                     expand = expand_scale(mult = c(0,0))) +
  labs(x = TeX("$t$"), y = TeX("$S(t)$")) + 
  general_theme
F_example_3 + S_example_3
```

## Función de Riesgo Acumulado

### Caso continuo {-}

Esta función, denotada por $H(t)$, es importante en la medición de la frecuencia con que ocurren los fallos en el tiempo y en el análisis de residuos para el ajuste de algunos modelos. $H(t)$ se define como sigue:

$$
H(t)=\int_{0}^{t}h(u)du
$$
Hemos visto anteriormente que:

$$
S(t)=exp(-H(t))
$$

entonces

$$
H(t)=-log(S(t))
$$

Podemos calcular a $f(t)$ en términos de $h(t)$ y $H(t)$:

$$
f(t)=h(t)S(t)=h(t)exp(-H(t))
$$

### Caso discreto {-}

$H(t)$ se define como:

$$
H(t)=\sum_{k: u_k\leq t}h(u_k)
$$

Una definición alternativa es:

$$
H(t)=-\sum_{k: u_k\leq t}log(1-h(u_k))
$$

[^3.1]: Aunque en la definición de $h(t)$ se tenga explícitamente la palabra "probabilidad", hay que tener en claro que esta función no es una función de probabilidad, si no tal cual una **tasa**, ya que la acumulación de esta puede dar valores superiores a 1.
[^3.2]: $\mathbb{P}(T\geq u_k) = \mathbb{P}(T>u_{k-1}) = S(u_{k-1})$ por el hecho de estar tratando con una variable discreta, ya que el siguiente valor de $u_{k-1}$ en la lista $\{u_1, \dots, u_{k-1}, u_{k}\}$ es $u_k$. Además, véase que el uso de $f_T(u_k)$ en este caso discreto es simplemente notación y no se debe confundir con la función de densidad de la v.a $T$.
[^3.3]: Véase que al mencionar que la variable $T$ es no negativa se da por entendido que dicha variable aleatoria en el espacio de probabilidad $(\Omega, S, \mathbb{P})$, donde $\Omega$ es el espacio muestral, $S$ la $\sigma$-álgebra definida en $\Omega$ y $\mathbb{P}$ la medida de probabilidad correspondiente, asigna valores en $\mathbb{R}^{+\{0\}}$; es decir: $T:\Omega\rightarrow\mathbb{R}^{+\{0\}}$.

<!--chapter:end:03_Survival_functions.Rmd-->

# Parámetros Poblacionales {#par-poblacionales}

Si conocemos la distribución de $T$ (cuando sea posible) es importante extraer cierta información que nos ayude a sacar conclusiones sobre los tiempos de supervivencia; a saber, información sobre su(s) parámetro(s). Aunque es habitual pensar a $T$ como una variable aleatoria continua, a continuación presentaremos parámetros poblacionales en términos de la función de superviviencia para el caso continuo y discreto.

## Media {#media}

### Caso continuo {-}

Para el caso continuo se tiene:

$$
\mu=\mathbb{E}[T]=\int_{0}^{\infty}\mathbb{P}(T>t)=\int_{0}^{\infty}S(t)dt
$$

La demostración se queda como ejercicio al alumno.

### Caso discreto {-}

$\mu$ en este caso es de la forma:

$$
\mu=\mathbb{E}[T]=\sum_{k=1}^{\infty}u_kf(u_k)=\sum_{k=1}^{\infty}S(u_k)
$$

La demostración se queda como ejercicio al alumno.

## Varianza

### Caso continuo {-}

Para este caso la varianza se ve como:

$$
  \sigma^2=Var[T]=\mathbb{E}[T^2]-(\mathbb{E}[T])^2=2\int_{0}^{\infty}tS(t)dt-\left(\int_{0}^{\infty}S(t)dt\right)^2
$$

La demostración de la igualdad anterior se obtiene si se observa que:

$$
\mathbb{E}[T^2]=\int_{0}^{\infty}t^2f(t)dt=-t^2S(t)|_0^{\infty}+2\int_{0}^{\infty}tS(t)dt=2\int_{0}^{\infty}tS(t)dt
$$

Y ocupando que:

$$
\mathbb{E}[T]=\int_{0}^{\infty}S(t)dt
$$

### Caso discreto {-}

De manera similar:

$$
  \sigma^2=Var[T]=\mathbb{E}[T^2]-(\mathbb{E}[T])^2=2\sum_{k=1}^{\infty}u_kS(u_k)-\left(\sum_{k=1}^{\infty}S(u_k)\right)^2
$$

La demostración se queda de ejercicio al alumno.

## Función de Media Residual

Para individuos de edad $x$ este parámetro, denotado por $mr(x)$, mide la esperanza de vida residual; esto es, "la esperanza de vida que les queda a partir de la edad $x$".

### Caso continuo {-}

Se define como:

$$
mr(x)=\mathbb{E}[T-x|T>x]=\frac{\mathbb{E}[T-x]}{\mathbb{P}(T>x)}=\frac{\int_x^{\infty}(t-x)f(t)dt}{S(x)}=\frac{\int_x^{\infty}S(t)dt}{S(x)}
$$

### Caso discreto {-}

Para este caso es:

$$
mr(u_x)=\frac{\sum_{k=x}^{\infty}S(u_k)}{S(u_x)}
$$

## Cuantiles de Orden $p$

El cálculo de diversos cuantiles nos permitirá hacer comparaciones entre diversos grupos de sujetos, además de obtener información sobre los tiempos de falla, por ejemplo, el tiempo mediano de falla (a veces es mejor el cálculo de la mediana que la media).

### Caso continuo {-}

El cuantil o percentil, $t_p$, de orden $p$ de la variable aleatoria continua $T$ será aquel que:

$$
S(t_p)=1-p
$$

Si queremos el tiempo mediano de los tiempos de supervivencia entonces debemos calcular $t_{0.5}$ talque:

$$
S(t_{0.5})=0.5
$$

### Caso discreto {-}

En este caso $t_p$ es:
$$
t_p=inf\{t: S(t) \leq  1-p\}
$$


#### Ejemplo 1 {-}

Siguiendo el ejemplo presentado en la sección \@ref(RiskFunction), se tiene lo siguiente:

+ Función de supervivencia de $T$: $S(t) = \mathbb{P}(T>t)=\left\{\begin{array}{ll}1 & \mbox{si }t=1\\\frac{2}{3} & \mbox{si } t=2\\\frac{1}{3} & \mbox{si } t = 3\\0 & \mbox{si }t>3\end{array}\right.$
+ Función de riesgo: $h(t) =\left\{\begin{array}{ll}\frac{1}{3} & \mbox{si }t=1\\\frac{1}{2} & \mbox{si } t=2\\\ 1 & \mbox{si } t = 3\end{array}\right.$
+ $\mu = \mathbb{E}(T) = \sum\limits_{t = 1}^3S(t) = \sum\limits_{t = 1}^3t\cdot f(t) = 2$.
+ $mrl(2) = \frac{\sum\limits_{k = 2}^\infty S(u_k)}{S(2)} = \frac{2/3+1/3+0}{2/3} = \frac{3}{2} = 1.5$.
+ $t_{0.75} = inf\{t: S(t) \leq  0.15\} = 3$

Con la finalidad de aclarar la distribución de los cuantiles en una distribución discreta, se dejan las siguientes gráficas correspondientes a este ejercicio.

```{r}
q_1 <- tibble(x = c(0,5)) %>% 
  ggplot(aes(x = x)) +
  annotate("segment", x = c(0,1,2,3), xend = c(1, 2, 3, 5), 
           y = c(0, 1/3, 2/3, 1), yend = c(0, 1/3, 2/3, 1)) +
  annotate("point", x = c(1, 2, 3), y = c(0, 1/3, 2/3),
           shape = 21, size = 3, color = "black", fill = "white") +
  annotate("point", x = c(1, 2, 3), y = c(1/3, 2/3, 1),
           shape = 19, size = 3, color = "black") + 
  # geom_text(aes(x = .5+.07, y = 0+.07, 
  #              label = TeX("$\\[t_0, t_{33})$", output = "character")), parse = TRUE)+
  #geom_text(aes(x = 1.5+.07, y = 1/3+.07,
  #          label = TeX("$\\[t_{33}, t_{66})$", output = "character")), parse = TRUE)+
  #geom_text(aes(x = 2.5+.07, y = 2/3+.07,
  #          label = TeX("$\\[t_{66}, t_{1})$", output = "character")), parse = TRUE)+
  #geom_text(aes(x = 3.5+.07, y = 1+.07,
  #          label = TeX("$t_{1}$", output = "character")), parse = TRUE)+
  annotate("text", x = c(.5,1.5, 2.5, 3.5), y =  c(0, 1/3, 2/3, 1)+.07, 
           label = c(TeX("$\\[t_0, t_{33})$"), TeX("$\\[t_{33}, t_{66})$"),
                     TeX("$\\[t_{66}, t_{1})$"), TeX("$t_{1}$")))+
  theme(axis.line = element_line(arrow =arrow(type = "closed", 
                       length = unit(0.1, "inches")))) +
  scale_y_continuous(breaks = c(0, 1/3, 2/3, 1), 
                     labels = c(0, TeX("$\\frac{1}{3}$"), TeX("$\\frac{2}{3}$"), "1"), limits = c(-.1,1.7), 
                     expand = expand_scale(mult = c(0,0))) +
  scale_x_continuous(breaks = c(1, 2, 3), 
                     labels = c(1, 2, 3), 
                     expand = expand_scale(mult = c(0,0))) +
  labs(x = TeX("$t$"), y = TeX("$F(t)$")) + 
  general_theme
q_2 <-  tibble(x = c(0,5)) %>% 
  ggplot(aes(x = x)) +
  annotate("segment", x = c(0,1,2,3), xend = c(1, 2, 3, 5), 
           y = 1-c(0, 1/3, 2/3, 1), yend = 1-c(0, 1/3, 2/3, 1)) +
  annotate("point", x = c(1, 2, 3), y = 1-c(0, 1/3, 2/3),
           shape = 21, size = 3, color = "black", fill = "white") +
  annotate("point", x = c(1, 2, 3), y = 1-c(1/3, 2/3, 1),
           shape = 19, size = 3, color = "black") + 
  # geom_text(aes(x = .5+.07, y = 0+.07, 
  #              label = TeX("$\\[t_0, t_{33})$", output = "character")), parse = TRUE)+
  #geom_text(aes(x = 1.5+.07, y = 1/3+.07,
  #          label = TeX("$\\[t_{33}, t_{66})$", output = "character")), parse = TRUE)+
  #geom_text(aes(x = 2.5+.07, y = 2/3+.07,
  #          label = TeX("$\\[t_{66}, t_{1})$", output = "character")), parse = TRUE)+
  #geom_text(aes(x = 3.5+.07, y = 1+.07,
  #          label = TeX("$t_{1}$", output = "character")), parse = TRUE)+
  annotate("text", x = c(.5,1.5, 2.5, 3.5), y =  1-c(0, 1/3, 2/3, 1)+.07, 
           label = c(TeX("$\\[t_0, t_{33})$"), TeX("$\\[t_{33}, t_{66})$"),
                     TeX("$\\[t_{66}, t_{1})$"), TeX("$t_{1}$")))+
  theme(axis.line = element_line(arrow =arrow(type = "closed", 
                       length = unit(0.1, "inches")))) +
  scale_y_continuous(breaks = c(0, 1/3, 2/3, 1), 
                     labels = c(0, TeX("$\\frac{1}{3}$"), TeX("$\\frac{2}{3}$"), "1"), limits = c(-.1,1.7), 
                     expand = expand_scale(mult = c(0,0))) +
  scale_x_continuous(breaks = c(1, 2, 3), 
                     labels = c(1, 2, 3), 
                     expand = expand_scale(mult = c(0,0))) +
  labs(x = TeX("$t$"), y = TeX("S(t)$")) + 
  general_theme
q_1 + q_2
```

#### Ejemplo 2 {-}

Sea $T$ una v.a con distribución uniforme continua en $(0,100)$ unidades días.

1. Encontrar la función de supervivencia y evaluar la supervivencia para 30 y 35 años.
2. Encontrar la función de riesgo y evaluar el riesgo para 60 días.
3. Encontrar la esperanza de riesgo residual a los 75 días.

Soluciones:

1.
$$
f_T(t) = \left\{
\begin{array}{ll}
\frac{1}{100} & \forall\ \ t\in [0,100]\\
0 & e.o.c
\end{array}
\right.
\implies S(t) = 1-\int_0^t\frac{1}{100}dv = 1-\frac{t}{100}
$$
$$
\implies S(30) = \mathbb{P}(T>30) = 1-\frac{30}{100};\ \  S(35) = 1- \frac{35}{100}
$$
2. 
$$
h(t) = \frac{f(t)}{S(t)} = \frac{\frac{1}{100}}{1-\frac{1}{100}} = \frac{1}{100-t}\\
\implies h(60) = \frac{1}{100-60} = \frac{1}{40}
$$
3.
$$
mrl(x) = \mathbb{E}(T-75 | T>75) = \frac{\mathbb{E}(T-75)}{\mathbb{P}(T>75)} = \frac{\int_x^\infty(t-75)f(t)dt}{S(75)} = \frac{\int_x^{100}(t-75)\frac{1}{100}dt}{1-\frac{75}{100}}
$$
$$
\implies mrl(75) = \frac{1}{25}\int_{75}^{100}(t-75)dt = \frac{1}{25}\left(\frac{100^2}{2}-\frac{75^2}{2}\right)-\frac{75(100-75)}{25} = \frac{25}{2} = 12.5
$$
Otra solución

Demostrandose que $\int_x^\infty(t-x)f(t) dt = \int_x^\infty S(t)dt$

$$
\implies mrl(75) = \frac{\int_{75}^{100}(t-75)\frac{1}{100}dt}{S(75)} = \frac{\int_{75}^{100}S(75)dt}{S(75)} = 12.5
$$

<!--chapter:end:04_PParameters.Rmd-->

# Modelos Paramétricos

Existen varios modelos paramétricos que se emplean en el análisis de supervivencia, esto se debe a que pueden representar de manera adecuada el comportamiento de ciertos fenómenos. La motivación para usar un modelo en particular es, por lo general, empírica; o bien, con base en la información que proporcione algún modelo **No paramétrico**. Las familias paramétricas más importantes son: *Exponencial, Weibull, Log-Normal, Log-logística* y *Gamma*.

## Modelo Exponencial

El modelo exponencial es el más importante debido a su amplia aplicación, por ejemplo, puede emplearse en estudios para determinar el tiempo de vida útil de algunos artículos manufacturados. Este modelo juega un papel fundamental análogo a la *distribución normal* en la inferencia estadística tradicional.

**Función de Densidad**

$$
f(t)=h(t)S(t)=\lambda exp(-\lambda t)=\lambda e^{-\lambda t}
$$
Para esta distribución $\lambda$ es un parámetro que modifica la escala de la distribución. Este es comúnmente llamado **_tasa_** definido por $1/s$ donde $s$ es el verdadero parámetro de escala[^5.1] de la distribución. Es muy común utilizar este parámetro en lugar del parámetro de escala ya que simplifica la expresión matemática.

**Función de Supervivencia**

$$
S(t)=exp\left(-\int_0^{t}h(u)du\right)=exp\left(-\int_0^{t}\lambda du\right)=exp(-\lambda t)=e^{-\lambda t}
$$

Si asumimos **una tasa de riesgo invariante en el tiempo**, $h(t)=\lambda$ con $\lambda>0$, generamos el modelo exponencial:

**Función de Riesgo**

Tomamos $\lambda>0$ y hacemos:

$$
h(t)=\lambda
$$

Aunque el supuesto de una función de riesgo constante resulta ser una restricción considerable, el modelo exponencial no deja de ser útil e importante en variedad de aplicaciones. Cabe destacar, que este modelo cumple con la propiedad de *pérdida de memoria*; a saber, se cumple que:

$$
\mathbb{P}(T>t+x|T>t)=\mathbb{P}(T>x)
$$


**Parámetros**

Si $T\sim Exp(\lambda)$ entonces:

$$
\mathbb{E}[T]=\int_{0}^{\infty}t\lambda e^{-\lambda t}dt=\frac{1}{\lambda}
$$

Y

$$
Var[T]=\mathbb{E}[T^2]-\mathbb{E}[T]^2=\frac{2}{\lambda^2}-\frac{1}{\lambda^2}=\frac{1}{\lambda^2}
$$

**Gráficas**

A continuación se muestran gráficas de una $Exponencial$ con $\lambda=0.5$

```{r}
exponential_example_1 <- tibble(x = c(0,20)) %>% 
  ggplot(aes(x = x))+stat_function(fun = ~1-pexp(.x,rate = .5)) +
  general_theme + 
  labs(x = TeX("$t$"), y = TeX("S(t)"))+
  ggtitle("Función de Supervivencia")+
  theme(text = element_text(size=9))
exponential_example_2 <- tibble(x = c(0,20)) %>% 
  ggplot(aes(x = x))+stat_function(fun = ~dexp(.x,rate = .5)) +
  general_theme + 
  labs(x = TeX("$t$"), y = TeX("f(t)"))+
  ggtitle("Función de Densidad")+
  theme(text = element_text(size=9))
exponential_example_3 <- tibble(x = c(0,20)) %>% 
  ggplot(aes(x = x))+stat_function(fun = ~rep(.5,length(.x))) +
  general_theme + 
  labs(x = TeX("$t$"), y = TeX("h(t)"))+
  ggtitle("Función de Riesgo")+
  theme(text = element_text(size=9))
exponential_example_1+exponential_example_2+exponential_example_3
```

**R**

En el lenguaje de programación `R` se pueden obtener resultados de esta distribución como una muestra pseudo aleatoria y aproximaciones numéricas para la distribución y densidad de esta así como la obtención de los cuantiles. 

En general, el sufijo para esta distribución es `*exp`, de tal manera que se tienen las siguientes funciones mencionando la interpretación de sus resultados:

+ `rexp(n, rate = 1)`: Muestra pseudo aleatoria de tamaño $n$.
+ `dexp(x, rate = 1, log = FALSE)`: Valores de $f(x)$.
+ `pexp(q, rate = 1, lower.tail = TRUE, log.p = FALSE)`: Valores de $F(x)$.
+ `qexp(p, rate = 1, lower.tail = TRUE, log.p = FALSE)`: Cuantil $t_p$. 

Algo que hay que recordar es que al utilizar la función, por ejemplo, `rexp(n, r)` se respeta el orden de los parámetros por lo que `r` será el valor correspondiente a la tasa y no parámetro de escala es decir el valor $r = \lambda$. Se menciona esta por que puede ser común que se confunda `r` con $1/\lambda$, por lo que se recomienda tener precaución.

## Modelo Weibull

El modelo Weibull es una generalización del modelo exponencial, se agrega un parámetro de forma[^5.2] $\gamma$ y se mantiene el parámetro de escala $\lambda$. Este modelo es uno de los más utilizados para tiempos de falla: tiene utilidad en la vida de algunos artículos manufacturados, así como en los tiempos de aparición de tumores en medicina.

**Función de Densidad**
$$
f(t)=\lambda \gamma(\lambda t)^{\gamma-1}e^{-(\lambda t)^\gamma}=h(t)S(t)
$$

Obsérvese que si $\gamma =1$ entonces el modelo Weibull se reduce al modelo exponencial.

**Función de Supervivencia**

$$
S(t)=exp\left(-\int_0^{t}h(u)du\right)=exp\left(-\int_0^{t}\lambda \gamma(\lambda u)^{\gamma-1} du\right)=exp(-(\lambda t)^\gamma)=e^{-(\lambda t)^\gamma}
$$

Si asumimos, en general, una **función de riesgo monótona: creciente o decreciente**, se puede obtener el modelo Weibull. 

**Función de Riesgo**

Para este modelo $h(t)$ está dada por:

$$
h(t)=\lambda \gamma(\lambda t)^{\gamma-1}; \ \ \ \gamma>0, \lambda>0 \mbox{ y } t>0
$$

**Parámetros**

Si $T\sim Weibull(\gamma,\lambda)$ entonces:

$$
\mathbb{E}[T]=\frac{1}{\lambda}\Gamma\left(\frac{1}{\gamma}+1\right)
$$

Y además

$$
Var[T]=\frac{1}{\lambda^2}\Gamma\left(\frac{2}{\gamma}+1\right)-\left(\frac{1}{\lambda}\Gamma\left(\frac{1}{\gamma}+1\right)\right)^2
\\=\frac{1}{\lambda^2}\left[\Gamma\left(\frac{2}{\gamma}+1\right)-\left(\Gamma\left(\frac{1}{\gamma}+1\right)\right)^2\right]
$$
Debe resultar sencillo para el alumno demostrar las igualdades de la esperanza y varianza.

**Gráficas**

Las dos gráficas siguientes muestran curvas de $f(t)$ y $h(t)$ para el modelo Weibull con $\lambda=1$ y $\gamma=2,4$:

```{r}
weibull_risk <- tibble(x = c(0,4)) %>% 
  ggplot(aes(x = x)) + 
  stat_function(aes(color = "2"), key_glyph='rect',
                fun = ~dweibull(.x,shape=2,scale =1)/(1-pweibull(.x,shape=2,scale=1)))+
  geom_line(data = tibble(x=seq(0,2,0.1), 
                          y = dweibull(x,shape=4,scale =1)/(1-pweibull(x,shape=4,scale =1))),
            aes(x = x, y = y, color = "1"), key_glyph='rect')+
  guides(color = guide_legend(title=NULL))+
  general_theme+
  theme(legend.key = element_rect(colour = 'gray98', size = 2),
        legend.position = c(.65, .35), 
        legend.background = element_blank(),
        legend.direction = "vertical",
        legend.spacing.x = unit(.2, 'cm'))+
  scale_color_manual(values = c(futurevisions("hd")[1], "firebrick"),
                     labels = unname(TeX(c("$\\gamma = 4$, $\\lambda = 1$",
                                           "$\\gamma = 2$, $\\lambda = 1$"))))+
  lims(y = c(0,8))+
  labs(x = TeX("$t$"), y = TeX("$h(t)$"))+
  ggtitle("Función de Riesgo")


weibull_density<- tibble(x = c(0,4)) %>% 
  ggplot(aes(x = x)) + 
  stat_function(aes(color = "1"), fun = ~dweibull(.x,shape=4,scale =1), key_glyph='rect')+
  stat_function(aes(color = "2"), fun = ~dweibull(.x,shape=2,scale =1), key_glyph='rect')+
  guides(color = guide_legend(title=NULL))+
  general_theme+
  theme(legend.key = element_rect(colour = 'gray98', size = 2),
        legend.position = c(.65, .35), 
        legend.background = element_blank(),
        legend.direction = "vertical",
        legend.spacing.x = unit(.2, 'cm'))+
  scale_color_manual(values = c(futurevisions("hd")[1], "firebrick"),
                     labels = unname(TeX(c("$\\gamma = 4$, $\\lambda = 1$",
                                           "$\\gamma = 2$, $\\lambda = 1$"))))+
    labs(x = TeX("$t$"), y = TeX("$f(t)$"))+
    ggtitle("Función de Densidad")
weibull_density+weibull_risk
```

Y para el modelo Weibull con $\lambda=1$ y $\gamma=0.5,1$ se tienen las siguientes gráficas:

```{r}
weibull_risk_2 <- tibble(x = c(0,4)) %>% 
  ggplot(aes(x = x)) + 
  #key_glyph para modificar la forma de la clave de la leyenda
  stat_function(aes(color = "2"), key_glyph='rect',
                fun = ~dweibull(.x,shape=0.5,scale =1)/(1-pweibull(.x,shape=0.5,scale =1)))+
  stat_function(aes(color = "1"), key_glyph='rect',
                fun = ~rep(1,length(.x)))+
  guides(color = guide_legend(title=NULL))+
  general_theme+
  #Para simular el espacio entre las claves de las leyendas
  theme(legend.key = element_rect(colour = 'gray98', size = 2),
        legend.position = c(.65, .45), 
        legend.background = element_blank(),
        legend.text.align = 0,
        legend.direction = "vertical",
        legend.spacing.x = unit(.2, 'cm'))+
  scale_color_manual(values = c("dodgerblue", "red3"),
                     labels = unname(TeX(c("$\\gamma = 1$, $\\lambda = 1$",
                                           "$\\gamma = 0.5$, $\\lambda = 1$"))))+
  lims(y = c(0,1.5))+
  labs(x = TeX("$t$"), y = TeX("$h(t)$"))+
  ggtitle("Función de Riesgo")


weibull_density_2 <- tibble(x = c(0,4)) %>% 
  ggplot(aes(x = x)) + 
  #key_glyph para modificar la forma de la clave de la leyenda
  stat_function(aes(color = "1"), fun = ~dweibull(.x,shape=1,scale =1), key_glyph='rect')+
  geom_line(data = tibble(x = seq(0.123717, 4,0.1),
                          y = dweibull(x,shape=0.5,scale =1)),
            aes(x = x, y = y, color = "2"), key_glyph='rect')+
  guides(color = guide_legend(title=NULL))+
  general_theme+
  #Para simular el espacio entre las claves de las leyendas
  theme(legend.key = element_rect(colour = 'gray98', size = 2),
        legend.position = c(.65, .45), 
        legend.background = element_blank(),
        legend.direction = "vertical",
        legend.text.align = 0,
        legend.spacing.x = unit(.2, 'cm'))+
  scale_color_manual(values = c("dodgerblue", "red3"),
                     labels = unname(TeX(c("$\\gamma = 1$, $\\lambda = 1$",
                                           "$\\gamma = 0.5$, $\\lambda = 1$")))) +
  labs(x = TeX("$t$"), y = TeX("$f(t)$")) +
  ggtitle("Función de Densidad") +
  lims(y=c(0,1)) 

weibull_density_2+weibull_risk_2
```

Como bien hemos dicho, si suponemos una función de riesgo monótona creciente ó decreciente la distribución Weibull puede ser generada. Concretamente, si $\gamma>1$ entonces $h(t)$ es estrictamente creciente, si $\gamma<1$ entonces $h(t)$ es estrictamente decreciente. Cuando $\gamma=1$ se tiene la distribución exponencial.

**R**

Para este caso el sufijo referente a esta distribución es `*weibull`, de tal manera que se tienen las siguientes funciones mencionando la interpretación de sus resultados:

+ `rweibull(n, shape, scale = 1)`: Muestra pseudo aleatoria de tamaño $n$.
+ `dweibull(x, shape, scale = 1, log = FALSE)`: Valores de $f(x)$.
+ `pweibull(q, shape, scale = 1, lower.tail = TRUE, log.p = FALSE)`: Valores de $F(x)$.
+ `qweibull(p, shape, scale = 1, lower.tail = TRUE, log.p = FALSE)`: Cuantil $t_p$. 

Así como en el caso de la exponencial y en todos los casos posteriores, se respeta el orden de los parámetros por lo que para aplicar los parámetros tal como se vieron en esta sección se puede utilizar esta función de la siguiente manera: `dweibull`($\gamma$, $1/\lambda$) o sin importar el orden indicando de manera explicita que `shape` = $\gamma$ y `scale` = $1/\lambda$. Esto último debido a que la función de densidad para este modelo en R esta considerada como $f(x) = \frac{\gamma}{\lambda}(\frac{x}{\lambda})^{\gamma-1}e^{-(\frac{x}{\lambda})^\gamma}$.

## Modelo Log-Normal

El modelo Log-Normal tiene estrecha relación con la distribución *Normal*. De hecho, el tiempo de supervivencia $T$ se dice que sigue una distribución Log-Normal, si $Y=ln(T)$ se distribuye $N(\mu,\sigma^2)$.

La distribución Log-Normal se ha utilizado como modelo en el tiempo de falla de aislantes eléctricos y en el tiempo de aparición de cáncer pulmonar. También se utiliza en poblaciones que son una mezcla de tiempos de vida cortos y largos. A pesar de esto, este modelo es criticado por ser decreciente para valores grandes de $t$, lo cual parece inadecaudo en algunas situaciones.

**Función de Densidad**

Para este modelo, $f(t)$ está dada por:

$$
f(t)=\frac{1}{\sqrt {2\pi}\sigma t}exp\left(-\frac{1}{2}\left(\frac{ln(t)-\mu}{\sigma}\right)^2\right)
$$

En este caso, $\mu$ y $\sigma$ pasan a ser los parámetros de escala y de forma de la distribución, los cuales hacen diferencia con los de la distribución normal, ya que en tal caso $\mu$ sería un parámetro de localización y $\sigma$ seguiría siendo el parámetro de escala. Para agregar un parámetro de localización a la distribución $log-normal$ bastaría camiar $x$ por $x-\theta$ donde $\theta$ sería tal parámetro.

**Función de Supervivencia**

$$
S(t)=\int_t^{\infty}f(u)du
\\=1-\int_0^{t}f(u)du
\\=1-\int_0^{t}\frac{1}{\sqrt {2\pi}\sigma u}exp\left(-\frac{1}{2}\left(\frac{ln(u)-\mu}{\sigma}\right)^2\right)du
$$

Tomando la notación de la función de distribución de una *Normal estándar*, $\Phi()$, se tiene:

$$
S(t)=1-\Phi\left(\frac{ln(t)-\mu}{\sigma}\right)
$$

**Función de Riesgo**

$$
h(t)=\frac{f(t)}{S(t)}
\\=\frac{\frac{1}{\sqrt {2\pi}\sigma t}exp\left(-\frac{1}{2}\left(\frac{ln(t)-\mu}{\sigma}\right)^2\right)}{1-\Phi\left(\frac{ln(t)-\mu}{\sigma}\right)}
$$

Si bien la expresión de $h(t)$ parece ser complicada, su gráfica resulta ser más interesante. Ésta toma el valor de cero en $t=0$, crece hasta un valor máximo y luego tiende a cero cuando $t \rightarrow \infty$. Véase sección de gráficas. 

**Parámetros**

Si $T\sim LogNormal(\mu,\sigma^2)$ entonces:

$$
\mathbb{E}[T]=exp\left(\mu+\frac{\sigma^2}{2}\right)
$$

Y además

$$
Var[T]=exp(2\mu+2\sigma^2)-exp(2\mu+\sigma^2)
$$

La demostración de las igualdades de media y varianza se dejan al alumno.

**Gráficas**

A continuación algunos ejemplos de las gráficas de $f(t)$ y $h(t)$ para la distribución Log-Normal:

```{r}
log_normal_density <- tibble(x = c(0,4)) %>% 
  ggplot(aes(x = x)) + 
  #key_glyph para modificar la forma de la clave de la leyenda
  stat_function(aes(color = "1"), fun = ~dlnorm(.x,0,0.1), key_glyph='rect')+
  stat_function(aes(color = "2"), fun = ~dlnorm(.x,0,0.5), key_glyph='rect')+
  stat_function(aes(color = "3"), fun = ~dlnorm(.x,0.5,0.5), key_glyph='rect')+
  stat_function(aes(color = "4"), fun = ~dlnorm(.x,1,0.5), key_glyph='rect')+
  guides(color = guide_legend(title=NULL))+
  general_theme+
  #Para simular el espacio entre las claves de las leyendas
  theme(legend.key = element_rect(colour = 'gray98', size = 2),
        legend.position = c(.7, .8), 
        legend.background = element_blank(),
        legend.direction = "vertical",
        legend.text.align = 0,
        legend.spacing.x = unit(.2, 'cm'),
        legend.key.size = unit(.4, "cm"))+
  scale_color_manual(values = c("1" = "salmon4","2" = "royalblue1","3" = "red3","4" = "darkgreen"),
                     labels = unname(TeX(c("$\\mu = 0$, $\\sigma^2 = 0.1$",
                                           "$\\mu = 0$, $\\sigma^2 = 0.5$",
                                           "$\\mu = 0.5$, $\\sigma^2 = 0.5$",
                                           "$\\mu = 1$, $\\sigma^2 = 0.5$")))) +
  labs(x = TeX("$t$"), y = TeX("$f(t)$")) +
  ggtitle("Función de Densidad")

log_normal_risk <- tibble(x = c(0,6)) %>% 
  ggplot(aes(x = x)) + 
  #key_glyph para modificar la forma de la clave de la leyenda
  stat_function(aes(color = "1"), 
                fun = ~(dlnorm(.x,0,1))/(s_y01= 1-plnorm(.x,0,1)), key_glyph='rect')+
  stat_function(aes(color = "2"), 
                fun = ~(dlnorm(.x,0,1.4))/(1-plnorm(.x,0,1.4)), key_glyph='rect')+
  stat_function(aes(color = "3"), 
                fun = ~(dlnorm(.x,1,1))/(s_y11= 1-plnorm(.x,1,1)), key_glyph='rect')+
  stat_function(aes(color = "4"), 
                fun = ~(dlnorm(.x,0.3,1))/(1-plnorm(.x,0.3,1)), key_glyph='rect')+
  guides(color = guide_legend(title=NULL))+
  general_theme+
  #Para simular el espacio entre las claves de las leyendas
  theme(legend.key = element_rect(colour = 'gray98', size = 2),
        legend.position = c(.77, .8), 
        legend.background = element_blank(),
        legend.direction = "vertical",
        legend.text.align = 0,
        legend.spacing.x = unit(.2, 'cm'),
        legend.key.size = unit(.4, "cm"))+
  scale_color_manual(values = c("1" = "salmon4","2" = "purple3","3" = "tomato2","4" = "dodgerblue4"),
                     labels = unname(TeX(c("$\\mu = 0$, $\\sigma^2 = 1$",
                                           "$\\mu = 0$, $\\sigma^2 = 1.4$",
                                           "$\\mu = 1$, $\\sigma^2 = 1$",
                                           "$\\mu = 0.3$, $\\sigma^2 = 1$")))) +
  labs(x = TeX("$t$"), y = TeX("$h(t)$")) +
  ggtitle("Función de Riesgo")

log_normal_density+log_normal_risk
```

**R**

Para esta distribución el sufijo respectivo será `*lnorm`, de tal manera que se tienen las siguientes funciones mencionando la interpretación de sus resultados:

+ `rlnorm(n, meanlog = 0, sdlog = 1)`: Muestra pseudo aleatoria de tamaño $n$.
+ `dlnorm(x, meanlog = 0, sdlog = 1, log = FALSE)`: Valores de $f(x)$.
+ `plnorm(q, meanlog = 0, sdlog = 1, lower.tail = TRUE, log.p = FALSE)`: Valores de $F(x)$.
+ `qlnorm(p, meanlog = 0, sdlog = 1, lower.tail = TRUE, log.p = FALSE)`: Cuantil $t_p$. 

En este caso, es evidente que `meanlog` correspondería al parámetro de escala $\mu$ y `sdlog` al parámetro de forma $\sigma$. Finalmente se menciona que estos parámetros no se deben confundir explícitamente con los de una distribución normal.

#### Ejemplo {-}

El tiempo de muerte en días después de un trasplante de médula sigue una distribución $log-normal$ con $\mu = 3.177, \sigma = 2.084$. Calcular lo siguiente

1. La media y la mediano tiempo de muerte
2. La probabilidad de que un individuo sobreviva 200 días después de un trasplante.

Soluciones

1. 
  + Mediana: $t_{0.5} =e^{\mu}$ cuando $T\sim log-normal \implies$ Mediana de tiempo de muerte: $t_{0.5} = e^{3.177} = 23.97$.
  + Media: $\mathbb{E}(T) = e^{\mu+\sigma^2/2}$ cuando $T\sim log- normal \implies$ Media de tiempo de muerte: $\mathbb{E}(T) = e^{3.177+\frac{(2.084)^2}{2}} = 210.29$ días.

Entonces si sobrevivieron 23.97, queda una gran cantidad de días donde, en promedio son 210.29.

2. $S(200) = 1-\Phi\left(\frac{\ln(200)-3.177}{2.084}\right) = 1-0.8438 = 0.15436$.

## Modelo Log-Logístico

El modelo Log-Logístico es derivado de la distribución *Logística*. Se dice que $T$ tiene distribución Log-Logística si $Y=ln(T)$ sigue una distribución Logística con parámetros $\mu$ y $\sigma ^2$.

**Función de Densidad**

$$
f(t)=\frac{\alpha \lambda (\lambda t)^{\alpha-1}}{(1+(\lambda t)^\alpha)^2}
$$

con $\alpha=\frac{1}{\sigma}$ y $\lambda=exp(-\frac{\mu}{\sigma})>0$. $\alpha$ es el parámetro de forma y $\lambda$ es el parámetro de escala.


**Función de Supervivencia**

$$
S(t)=\frac{1}{1+(\lambda t)^\alpha}
$$

**Función de Riesgo**

$$
h(t)=\frac{f(t)}{S(t)}=\frac{\alpha \lambda (\lambda t)^{\alpha-1}}{1+(\lambda t)^\alpha}
$$

La función de riesgo es monótona decreciente para $\alpha \leq 1$, y para $\alpha> 1$ la función de riesgo crece hasta alcanzar un máximo en $t=(\frac{\alpha-1}{\lambda})^{\frac{1}{\alpha}}$ y luego decrece a cero cuando $t \rightarrow \infty$.

**Gráficas**

Algunos ejemplos de las gráficas de $f(t)$ y $h(t)$ para la distribución Log-Logística:

```{r}
log_log_density <- tibble(x = c(0,5)) %>% 
  ggplot(aes(x = x)) + 
  #key_glyph para modificar la forma de la clave de la leyenda
  stat_function(aes(color = "1"), fun = ~dllogis(.x,2,1), key_glyph='rect')+
  stat_function(aes(color = "2"), fun = ~dllogis(.x,1,2), key_glyph='rect')+
  stat_function(aes(color = "3"), fun = ~dllogis(.x,1,0.5), key_glyph='rect')+
  guides(color = guide_legend(title=NULL))+
  general_theme+
  #Para simular el espacio entre las claves de las leyendas
  theme(legend.key = element_rect(colour = 'gray98', size = 2),
        legend.position = c(.73, .8), 
        legend.background = element_blank(),
        legend.direction = "vertical",
        legend.text.align = 0,
        legend.spacing.x = unit(.2, 'cm'),
        legend.key.size = unit(.4, "cm"))+
  scale_color_manual(values = c("1" = "firebrick3", "2" = "deepskyblue4", "3" = "forestgreen"),
                     labels = unname(TeX(c("$\\alpha = 2$, $\\lambda = 1$",
                                           "$\\alpha = 1$, $\\lambda = 2$",
                                           "$\\alpha = 1$, $\\lambda = 0.5$")))) +
  labs(x = TeX("$t$"), y = TeX("$f(t)$")) +
  ggtitle("Función de Densidad") +
  lims(y=c(0,.7)) 

log_log_risk <- tibble(x = c(0,6)) %>% 
  ggplot(aes(x = x)) + 
  #key_glyph para modificar la forma de la clave de la leyenda
  stat_function(aes(color = "1"), key_glyph='rect',
                fun = ~dllogis(.x,2,1)/(1-pllogis(.x,2,1)))+
  stat_function(aes(color = "2"), key_glyph='rect',
                fun = ~dllogis(.x,1,1)/(1-pllogis(.x,1,1)))+
  stat_function(aes(color = "3"), key_glyph='rect',
                fun = ~dllogis(.x,1,0.5)/(1-pllogis(.x,1,0.5)))+
  guides(color = guide_legend(title=NULL))+
  general_theme+
  #Para simular el espacio entre las claves de las leyendas
  theme(legend.key = element_rect(colour = 'gray98', size = 2),
        legend.position = c(.73, .8), 
        legend.background = element_blank(),
        legend.text.align = 0,
        legend.direction = "vertical",
        legend.spacing.x = unit(.2, 'cm'),
        legend.key.size = unit(.4, "cm"))+
  scale_color_manual(values = c("1" = "firebrick3", "2" = "deepskyblue4", "3" = "forestgreen"),
                     labels = unname(TeX(c("$\\alpha = 2$, $\\lambda = 1$",
                                           "$\\alpha = 1$, $\\lambda = 2$",
                                           "$\\alpha = 1$, $\\lambda = 0.5$")))) +
  lims(y = c(0,1))+
  labs(x = TeX("$t$"), y = TeX("$h(t)$"))+
  ggtitle("Función de Riesgo")

log_log_density+log_log_risk
```

**R**

Para esta distribución se recomienda descargar y utilizar el paquete `actuar`, en la cual vienen un conjunto de funciones similares a las anteriores, de hecho el sufijo respectivo será `*llogis` y, de manera análoga a las anteriores funciones, se tiene lo siguiente:

+ `rllogis(n, shape, rate = 1, scale = 1/rate)`: Muestra pseudo aleatoria de tamaño $n$.
+ `dllogis(x, shape, rate = 1, scale = 1/rate, log = FALSE)`: Valores de $f(x)$.
+ `pllogis(q, shape, rate = 1, scale = 1/rate, lower.tail = TRUE, log.p = FALSE)`: Valores de $F(x)$.
+ `qllogis(p, shape, rate = 1, scale = 1/rate, lower.tail = TRUE, log.p = FALSE)`: Cuantil $t_p$. 

En este caso, como en la exponencial y la weibull, `rate` correspondería al parámetro  $\lambda$ y `shape` al parámetro de forma $\alpha$.

## Modelo Gamma

La distribución Gamma, que incluye a las distribuciones *exponencial* y *ji-cuadrada*, ha sido utilizada como un modelo para problemas de confiabilidad industrial, hepatogramas en adultos normales y en pacientes con cirrosis, en supervivencia de plaquetas, entre otros. Este modelo tiene dos parámetros: $\beta$ es el parámetro de forma y $\lambda$ es el parámetro que modifica de escala; estrictamente hablando $\lambda$ es la tasa: $\lambda =\frac{1}{s}$ donde $s$ sería el verdadero parámetro de escala.

**Función de Densidad**

$f(t)$ está dada por:

$$
f(t)=\frac{\lambda^\beta}{\Gamma(\beta)}t^{\beta-1}exp(-\lambda t); \ \ \  \lambda,\beta>0
$$

**Función de Supervivencia**

$$
S(t)=1-Ig(\lambda t, \beta)
$$

donde[^5.3]:

$$
Ig(t,\beta)=\frac{1}{\Gamma(\beta)}\int_0^{t}u^{\beta-1}e^{-u}du
$$
Al igual que un modelo $Weibull(\lambda, alpha = 1)$, la distribución exponencial es un caso particular del modelo $Gamma(\lambda,\beta = 1)$. Cuando $\beta \rightarrow\infty$, modelo gamma se aproxima a una distribución normal.

**Función de Riesgo**

$$
h(t)=\frac{f(t)}{S(t)}=\frac{\frac{\lambda^\beta}{\Gamma(\beta)}t^{\beta-1}exp(-\lambda t)}{1-Ig(\lambda t, \beta)}
$$

Esta función de riesgo tiene distintos comportamientos:

+ Es **monótona creciente** para $\beta>1$. En este caso sucede que $h(0)=0$ y $\underset{t\rightarrow\infty}{h(t)} \rightarrow \lambda$. Además, la moda de la distribución es $t = \frac{\beta-1}{\lambda}$
+ Es **monótona decreciente** con $\beta <1$. En tal caso $h(0) = \infty$ y $\underset{t\rightarrow\infty}{h(t)} \rightarrow \lambda$.

**Parámetros**

Si $T\sim Gamma(\beta,\lambda)$ entonces:

$$
\begin{array}{ccc}
\mathbb{E}[T]=\frac{\beta}{\lambda} & \mbox{y} &
Var[T]=\frac{\beta}{\lambda^2}
\end{array}
$$

Las demostraciones de las igualdades de la esperanza y varianza se quedan de ejercicio al alumno.

**Gráficas**

Se muestran ejemplos de las gráficas de $f(t)$ y $h(t)$ para el modelo Gamma:

```{r}
gamma_density <- tibble(x = c(0,6)) %>% 
  ggplot(aes(x = x)) + 
  #key_glyph para modificar la forma de la clave de la leyenda
  stat_function(aes(color = "1"), fun = ~dgamma(.x,1,1), key_glyph='rect')+
  stat_function(aes(color = "2"), fun = ~dgamma(.x,2,1), key_glyph='rect')+
  stat_function(aes(color = "3"), fun = ~dgamma(.x,3,1/3), key_glyph='rect')+
  stat_function(aes(color = "4"), fun = ~dgamma(.x,3,1), key_glyph='rect')+
  guides(color = guide_legend(title=NULL))+
  general_theme+
  #Para simular el espacio entre las claves de las leyendas
  theme(legend.key = element_rect(colour = 'gray98', size = 2),
        legend.position = c(.73, .8), 
        legend.background = element_blank(),
        legend.direction = "vertical",
        legend.text.align = 0,
        legend.spacing.x = unit(.2, 'cm'),
        legend.key.size = unit(.4, "cm"))+
  scale_color_manual(values =  c("1" = "salmon4","2" = "royalblue1",
                                 "3" = "red3","4" = "darkgreen"),
                     labels = unname(TeX(c("$\\beta = 1$, $\\lambda = 1$",
                                           "$\\beta = 2$, $\\lambda = 1$",
                                           "$\\beta = 3$, $\\lambda = \\frac{1}{3}$",
                                           "$\\beta = 3$, $\\lambda = 1$")))) +
  labs(x = TeX("$t$"), y = TeX("$f(t)$")) +
  ggtitle("Función de Densidad") +
  lims(y=c(0,1)) 

gamma_risk <- tibble(x = c(0,28)) %>% 
  ggplot(aes(x = x)) + 
  #key_glyph para modificar la forma de la clave de la leyenda
  stat_function(aes(color = "1"), key_glyph='rect',
                fun = ~rep(1,length(.x)))+
  stat_function(aes(color = "2"), key_glyph='rect',
                fun = ~dgamma(.x,2,1)/(1-pgamma(.x,2,1)))+
  stat_function(aes(color = "3"), key_glyph='rect',
                fun = ~dgamma(.x,0.3,1)/(1-pgamma(.x,0.3,1)))+
  stat_function(aes(color = "4"), key_glyph='rect',
                fun = ~dgamma(.x,4,1)/(1-pgamma(.x,4,1)))+
  guides(color = guide_legend(title=NULL))+
  general_theme+
  #Para simular el espacio entre las claves de las leyendas
  theme(legend.key = element_rect(colour = 'gray98', size = 2),
        legend.position = c(.73, .8), 
        legend.background = element_blank(),
        legend.text.align = 0,
        legend.direction = "vertical",
        legend.spacing.x = unit(.2, 'cm'),
        legend.key.size = unit(.4, "cm"))+
  scale_color_manual(values = c("1" = "salmon4","2" = "royalblue1",
                                "3" = "tomato2","4" = "dodgerblue4"),
                     labels = unname(TeX(c("$\\beta = 1$, $\\lambda = 1$",
                                           "$\\beta = 2$, $\\lambda = 1$",
                                           "$\\beta = 0.3$, $\\lambda = 1$",
                                           "$\\beta = 4$, $\\lambda = 1$")))) +
  labs(x = TeX("$t$"), y = TeX("$h(t)$"))+
  ggtitle("Función de Riesgo")+
  scale_y_continuous(limits = c(0.6, 1.4), expand = expand_scale(mult = c(0,0)))
  
gamma_density+gamma_risk
```

**R**

Para esta distribución el sufijo respectivo será `*gamma`, de tal manera que se tienen las siguientes funciones mencionando la interpretación de sus resultados:

+ `rgamma(n, shape, rate = 1, scale = 1/rate)`: Muestra pseudo aleatoria de tamaño $n$.
+ `dgamma(x, shape, rate = 1, scale = 1/rate, log = FALSE)`: Valores de $f(x)$.
+ `pgamma(q, shape, rate = 1, scale = 1/rate, lower.tail = TRUE, log.p = FALSE)`: Valores de $F(x)$.
+ `qgamma(p, shape, rate = 1, scale = 1/rate, lower.tail = TRUE, log.p = FALSE)`: Cuantil $t_p$. 

Como en el caso de la exponencial, se recomienda tener precaución ya que el parámetro `rate` es el que corresponde al parámetro $\lambda$ en este trabajo.

## Modelo Gamma Generalizada

Finalmente, se presenta el modelo Gamma Generalizada con dos parámetros de forma y un parámetro de que modifica la escala $\alpha$, $\beta$ y $\lambda$ respectivamente.

**Función de Densidad**

$f(t)$ está dada por:

$$
f(t)=\frac{\alpha\lambda^{\beta\alpha}}{\Gamma(\beta)}t^{\alpha\beta-1}\exp(-\lambda t)^\alpha; \ \ \  \lambda,\alpha, \beta>0
$$

**Función de Supervivencia**

$$
S(t)=1-Ig((\lambda t)^\alpha, \beta)
$$

Esta distribución se reduce a las siguientes

+ $Exponencial$ cuando $\beta = \alpha = 1$.
+ $Weibull$ cuando $\beta = 1$.
+ $Gamma$ cuando $\alpha = 1$.
+ Tiende a la log-normal cuando $\beta\rightarrow\infty$.

**R**

Para esta distribución se recomienda descargar y utilizar el paquete `ggamma`, en la cual vienen un conjunto de funciones similares a las anteriores. Aquí el respectivo sufijo será `*ggamma` y, de manera análoga a las anteriores funciones, se tiene lo siguiente:

+ `rggamma(n, a, b, k)`: Muestra pseudo aleatoria de tamaño $n$.
+ `dggamma(x, a, b, k, log = F)`: Valores de $f(x)$.
+ `pggamma(p, a, b, k, lower.tail = TRUE, log.p = FALSE)`: Valores de $F(x)$.
+ `qggamma(p, shape, rate = 1, scale = 1/rate, lower.tail = TRUE, log.p = FALSE)`: Cuantil $t_p$. 

Para este caso, se tiene una parametrización de uso común en distintas fuentes. `a` = $\frac{1}{\lambda}$, `b` = $\alpha$ y `k` = $\beta$.

#### Ejemplo {-}

El tiempo de vida en meses de cierta especie de ratón sigue una distribución $gamma(\beta = 3, \lambda = 0.2)$.

1. Calcular la probabilidad de que un ratón sobreviva más de 18 meses. 
2. ¿Cuál es la probabilidad de que un ratón muera en el primer año de vida?
3. ¿Cuál es la esperanza de vida media de esta especia?

Soluciones 

1. $S(18) = 1-F(18) = 1-$ `r pgamma(18, 3, .2)` = `r 1-pgamma(18, 3, .2)`
2. $F(12) =$ `r pgamma(12, 3, .2)`
3. $\mathbb{E}(T) = \frac{\beta}{\lambda} = \frac{3}{0.2} = 15$ meses.

Cabe señalar que hasta este punto **no hemos introducido datos censurados a los modelos**.


[^5.1]: Un parámetro de escala modifica la escala o _dispersión_ de la distribución ya sea que entre mayor sea este parámetro mayor dispersión se tendrá o se tenga el caso contrario como en una _log-logistica_. En el siguiente [enlace](https://en.wikipedia.org/wiki/Scale_parameter) se puede encontrar mayor información sobre esto así como animaciones para un mejor entendimiento.
[^5.2]: Un parámetro de forma es aquel que no es de escala ni de localización o una función de estos, ya que su único propósito es modificar la forma de la distribución de manera distinta a estos anteriores, es decir que no sólo traslada o afecta la variabilidad de la misma.
[^5.3]: Esta función se llama _función gamma incompleta_ y en algunas fuentes se puede encontrar esta en particular como *__lower incomplete gamma function__*. Cuando se tiene $\int_x^{\infty}u^{\beta-1}e^{-u}du = \Gamma(x, \beta)$ se le conoce como *__upper incomplete gamma function__*, la cual es una [generalización](https://mathworld.wolfram.com/IncompleteGammaFunction.html) de la función gamma: $\Gamma(x, 0) = \Gamma(x)$. Originalmente esta función no tiene el cociente que se esta utilizando en este caso, esto es un efecto de normalizar la función como se puede ver en el siguiente [enlace](https://dlmf.nist.gov/8.2). Algunas veces esta función es conocida directamente como función gamma incompleta como en [@klein2006survival]

<!--chapter:end:05_ParametricModels.Rmd-->

# La Función de Verosimilitud con Censura y Truncamiento

Cuando se conoce la distribución de $T$, hacer estimaciones (usualmente por el método de máxima verosimilitud) sobre parámetros poblacionales resulta de suma importancia, pues a partir de ellos no sólo podemos conocer *estimadores* de la media, varianza o cuantiles; sino que también podemos conocer $\hat S(t)$, $\hat h(t)$, etc. En la sección anterior revisamos los modelos paramétricos más usados en análisis de supervivencia, sin embargo, no contemplamos datos censurados o truncados en dichos modelos. En este apartado veremos la función de verosimilitud considerando censura y truncamiento, y con base en esta función haremos estimaciones para algunas distribuciones.

## Caso General

De acuerdo al tipo de observación, se tienen las siguientes contribuciones a la función de verosimilitud:

$$
\begin{array}{ll}
\mbox{Exactas } T_{i} & f(t_{i})\\
\mbox{Censurada por la derecha } T_{i}>C_{i} & \mathbb{P}(T_{i}>C_{i})=S(C_{i})\\
\mbox{Censurada por la izquierda } T_{i}<C_{i} & \mathbb{P}(T_{i}<C_{i})=1-S(C_{i})\\
\mbox{Censurada por la intervalo } L_{i}<T_{i}\leq R_{i} & \mathbb{P}(L_{i}<T_{i}\leq R_{i})=S(L_{i})-S(R_{i})\\
\mbox{Truncado por la izquierda } T_{i}|T_{i}>u_{i} & \mathbb{P}(T_{i}|T_{i}>u_{i})=\frac{f(t_{i})}{S(u_{i})}\\
\mbox{Truncado por la derecha } T_{i}|T_{i} \leq v_{i} & \mathbb{P}(T_{i}|T_{i} \leq v_{i})=\frac{f(t_{i})}{1-S(v_{i})}\\
\end{array}
$$

Entonces la función de verosimilitud es: 

$$
\mathbf{\mathscr{L}} = \prod_{i\in D}f(t_{i})\prod_{i\in R}S(C_{i})\prod_{i\in L}(1-S(C_{i}))\prod_{i\in I}[S(L_{i})-S(R_{i})]
$$
donde 

+ D: Conjunto de tiempos de fallo.
+ R: Conjunto de observaciones censuradas por la derecha.
+ L: Conjunto de observaciones censuradas por la izquierda.
+ I: Conjunto de observaciones censuradas por intervalo.

Cuando hay datos truncados, se sustituye $f(t_{i})$ por $\frac{f(t_{i})}{S(u_{i})}$ y $S(C_{i})$ por $\frac{S(C_{i})}{S(_{u_{i}})}$.

## Censura por la Derecha Tipo I

Suponga que se tiene una muestra aleatoria de $n$ individuos con tiempos de vida $T_1,T_2,..., T_n$(v.a.i.i.d) y que está asociado a cada individuo un tiempo fijo de censura $C_i>0$. Se observa a $T_i$ solamente si $T_i\leq C_i$, por lo que los datos son parejas: $(t_i,\delta_i)$, $i=1,2,...,n$ donde $t_i=min(T_i,C_i)$ y:

$$
\delta_{i} = \left\{
\begin{array}{ll}
0 & \mbox{si }  t_{i} \ = \ C_i\\
1 & \mbox{si }  t_{i} \ =\ T_i
\end{array}
\right.
$$

Entonces la función de verosimilitud para datos con este tipo de censura es de la forma:

$$ 
\mathscr{L} = \prod^{n}_{i=1}f(t_{i})^{\delta_{i}}S(t_{i})^{1-\delta_{i}} 
$$

donde $\sum_{i=1}^{n}\delta_i$ representa el total de los tiempos de vida observados.

Considerando que $f(t) = h(t) S(t)$, entonces:

$$
\begin{split}
\mathscr{L} & =\prod_{i = 1}^{n}h(t_{i})^{\delta_{i}}S(t_{i})^{\delta_{i}}S(t_{i})^{1-\delta_{i}}\\
 & =\prod_{i = 1}^{n}h(t_{i})^{\delta_{i}}S(t_{i})\\
 & =\prod_{i = 1}^{n}h(t_{i})^{\delta_{i}}exp\{-H(t_{i})\}
\end{split}
$$

## Censura por la Derecha Tipo II

Supongamos que se observan los $r$ tiempos de falla $T_{(1)}< T_{(2)}< ...<T_{(r)}$ más pequeños, dejando a $n-r$ tiempos censurados por la derecha, de una muestra de tamaño $n$. De modo que, los datos serán los $r$ tiempos de fallo más pequeños de $T_{1}, T_{2},...,T_{n}$.

$T$ tiene f.d.p $f(t)$ y función de supervivencia $S(t)$. Entonces la f.d.p. conjunta de $T_{(1)}, T_{(2)}, ...,T_{(r)}$ es:

$$
\mathscr{L} = \frac{n!}{(n-r)!}\left\{\prod_{i=1}^{r}f(t_{i})\right\}\left[S\left(t_{(r)}\right)\right]^{n-r}
$$

donde $\prod_{i=1}^{r}f(t_{i})$ es la parte correspondiente a las $r$ fallas observadas y $[S(t_{(r)})]^{n-r}$ constituye la aportación de las observaciones censuradas después de la $r-esima$ falla observada.

Observemos que si quitamos el término constante $\frac{n!}{(n-r)!}$ y definiendo a la función indicadora:

$$
\delta_{i} = \left\{
\begin{array}{ll}
0 & \mbox{si  } T_{i} \ > \ T_{(r)}\\
1 & \mbox{si }  T_{i}  \leq\ T_{(r)}
\end{array}
\right.
$$

Entonces la función de verosimilitud para este tipo de censura se puede reesctibir:

$$ 
\mathscr{L} \propto \prod^{n}_{i=1}f(t_{i})^{\delta_{i}}S(t_{i})^{1-\delta_{i}} 
$$

que es la función de verosimilitud con datos censurados por la derecha tipo 1 revisada en la sección anterior.

## Censura Aleatoria

Supongamos que para cada individuo se tienen $T_i$ y $C_i$ variables aleatorias independientes, con funciones de densidad $f_{T}(t)$ y $f_{C}(t)$, y con funciones de superviviencia $S_{T}(t)$ y $S_{C}(t)$ respectivamente. Sean $(T_i,C_i)$, $i=1,2,...,n$ parejas de observaciones independientes, la variable que observamos es $t_i=min(T_i,C_i)$ y se define:

$$
\delta_{i} = \left\{
\begin{array}{ll}
0 & \mbox{si  } T_{i} \ > \ C_i\\
1 & \mbox{si }  T_{i}  \leq\ C_i
\end{array}
\right.
$$

por lo que, las observaciones son las parejas $(t_i,\delta_i)$ con $i=1,2,...,n$.

La función de verosimilitud es entonces:

$$ 
\mathscr{L} = \prod^{n}_{i=1}[S_C(t_{i})]^{1-\delta_{i}}[f_C(t_i)]^{\delta_i}[f_T(t_i)]^{\delta_i}[S_T(t_{i})]^{1-\delta_{i}} 
$$

Similar al caso se censura por la derecha tipo 2, se puede demostrar que la expresión anterior es proporcional a $\prod^{n}_{i=1}f_T(t_{i})^{\delta_{i}}S_T(t_{i})^{1-\delta_{i}}$.

## Truncamiento por la Izquierda

Consideremos los tiempos de fallo truncados por la izquierda, es decir, $T_{i}$ tal que $T_{i}\geq u_{i}$ para ser observado ($u_{i}$ es el valor de truncamiento).

En este caso, las observaciones serán $(u_{i}, t_{i},\delta_{i})$ con $t_{i}\geq u_{i}$ tiempo de fallo y $\delta_{i}$ indicador de censura por la derecha. Por lo que:

$$
\mathbf{\mathscr{L}} = \prod_{i=1}^{n}\left\{\frac{f(t_{i})}{S(u_{i})}\right\}^{\delta_{i}}\left\{\frac{S(t_{i})}{S(u_{i})}\right\}^{1-\delta_{i}}=\prod_{i=1}^{n}\left\{h(t_{i})\right\}^{\delta_{i}}\left\{\frac{S(t_{i})}{S(u_{i})}\right\}
$$

Obsérvese que el hecho de dividir la función de verosimilitud entre $S(u_{i})$ se limita a que los datos sean truncados por la izquierda[^6.1].

## Truncamiento por la Derecha

Consideremos tiempos de fallo $T_{i}$ tal que $T_{i} \leq v_{i}$ para que sea observado. Entonces las observaciones serán $(t_{i}, v_{i})$ para todo $i = 1,...,n$.

Por lo que:

$$
\mathbf{\mathscr{L}} = \prod_{i=1}^{n}\left\{\frac{f(t_{i})}{1-S(v_{i})}\right\} =\prod_{i=1}^{n} \mathbb{P}(T_{i}|T_{i}<v_{i})
$$

## Estimaciones para Algunos Modelos 

### Modelo Exponencial {-}

Sean los tiempos de fallo $T_{i}$ independientes y provenientes de una distribución exponencial:

+ $f(t) = \lambda e^{-\lambda t}$
+ $S(t) = e^{-\lambda t}$
+ $h(t) = \lambda$
+ $H(t) = \lambda t$

Entonces, la función de verosimilitud con censura tipo I es:

$$
\mathscr{L} = \prod_{i}^{n}\lambda^{\delta_{i}}e^{-\lambda t_{i}}= \lambda^{\sum_{i= 1}^{n}\delta_{i}}e^{-\lambda \sum_{i = 1}^{n}t_{i}}
$$

Sea $r=\sum_{i = 1}^{n}\delta_{i}$ el número de observaciones exactas (no censuradas). Entonces:

$$
 \mathscr{L} = \lambda^{r}e^{-\lambda\sum_{i= 1}^{n}t_{i}}
$$

Si queremos un estimador para $\lambda$, hacemos:

$$
\frac{\partial ln(\mathscr{L})}{\partial \lambda} = \frac{\partial[r ln(\lambda)-\lambda\sum_{i = 1}^{n}t_{i}]}{\partial\lambda} = \frac{r}{\lambda}-\sum_{i  =1}^{n}t_i = 0
$$

$$
\Longrightarrow \hat{\lambda} = \frac{r}{\sum_{i= 1}^{n}t_{i}}
$$

Observe que si *no hay datos censurados* entonces $\sum_{i = 1}^{n}\delta_{i}=n$, por lo que $\hat{\lambda}=\frac{1}{\bar t}$, y este es el estimador que conocemos desde el curso de inferencia.

#### Ejemplo {-}

El siguiente ejercicio fue basado en el ejercicio 3.6 del libro [@klein2006survival]. Los siguientes datos consisten en los tiempos de recaída y los tiempos de muerte después de la recaída de 10 pacientes con trasplante de médula ósea. Suponga que el tiempo hasta la recaída tiene una distribución exponencial con la tasa de riesgo $\lambda$.

```{r}
data_frame(Paciente = 1:10, "Tiempo de recaida en meses" = c("5","8","12","24","32","17","16+","17+","19+","30+")) %>% 
  kable( booktabs = T, align=rep('c')) %>% kable_styling(bootstrap_options = "striped", full_width = F) %>%
  footnote(general = "Los datos censurados están representados con un '+'", general_title = "")
```

+ a) Calcule la tasa de recaída.
+ b) Calcule la probabilidad de no recaer en 16 meses.

Sabemos que los estimadores máximo-verosímiles cumplen la propiedad de invarianza, de modo que:

a) $\hat{\lambda} = \frac{r}{\sum_{i= 1}^{n}t_{i}} = \frac{6}{\sum_{i= 1}^{10}t_{i}} = \frac{6}{180} = 3.3333333\%$ 

b) $\hat S(16) = e^{-\hat\lambda t}  = e^{-0.033(16)} = 0.5866463$

### Modelo Weibull {-}

Supongamos que se tienen los tiempos de fallo $T_{i}$ con censura, provenientes de una distribución Weibull:

+ $f(t) = \lambda \gamma(\lambda t)^{\gamma-1}e^{-(\lambda t)^\gamma}$
+ $S(t) = e^{-(\lambda t)^\gamma}$
+ $h(t) = \lambda \gamma(\lambda t)^{\gamma-1}$

Entonces, su respectiva función de verosimilitud es de la forma:

$$
\mathscr{L} = \prod_{i}^{n}\left[\lambda \gamma(\lambda t_i)^{\gamma-1}e^{-(\lambda t_i)^\gamma}\right]^{\delta_i}\left[e^{-(\lambda t_i)^\gamma}\right]^{1-\delta_i} = \prod_{i}^{n}\left[\lambda \gamma(\lambda t_i)^{\gamma-1}\right]^{\delta_i}\left[e^{-(\lambda t_i)^\gamma}\right]
$$

Por lo que:

$$
\ln(\mathscr{L}) = \sum_{i=1}^{n}\delta_i\ln(\lambda \gamma(\lambda t_i)^{\gamma -1})-(\lambda t_i)^\gamma
$$

Si suponemos que $r=\sum_{i = 1}^{n}\delta_{i}$ y desarrollamos la expresión anterior, obtenemos:

$$
\ln(\mathscr{L}) =r\ln(\lambda \gamma)+(\gamma -1)r\ln (\lambda)+(\gamma -1)\sum_{i=1}^{n}\delta_i\ln(t_i)-\lambda^{\gamma}\sum_{i=1}^{n}t_i^{\gamma}
$$

Los estimadores máximo-verosímiles de $\lambda$ y $\gamma$ se obtienen derivando $\ln(\mathscr{L})$ con respecto a $\lambda$ y $\gamma$, igualando a cero y evaluando en $\hat \lambda$ y $\hat \gamma$:

$$
\frac{\partial \ln(\mathscr{L})}{\partial \lambda}=r\frac{\gamma}{\lambda \gamma}+\frac{(\gamma-1)r}{\lambda}-\gamma \lambda^{\gamma -1}\sum_{i=1}^{n}t_i^{\gamma}=0
$$

$$
\frac{\partial \ln(\mathscr{L})}{\partial \gamma}=r\frac{\lambda}{\lambda \gamma}+r\ln(\lambda)+\sum_{i=1}^{n}\delta_i\ln(t_i)-\left[\lambda^{\gamma}\ln(\lambda)\sum_{i=1}^{n}t_i^{\gamma}+\lambda^\gamma \sum_{i=1}^{n}t_i^{\gamma}\ln(t_i)\right]=0
$$

Simplificando ambas ecuaciones tenemos:

$$
r\gamma-\gamma \lambda^\gamma\sum_{i=1}^{n}t_i^\gamma=0
$$

$$
\frac{r}{\gamma}+r\ln(\lambda)+\sum_{i=1}^{n}\delta_i\ln(t_i)-\lambda^\gamma\left[\ln(\lambda)\sum_{i=1}^{n}t_i^{\gamma}-\sum_{i=1}^{n}t_i^{\gamma}\ln(t_i)\right]=0
$$

Despejamos a $\lambda$ de la primera ecuación:

$$
\hat\lambda=\left(\frac{r}{\sum_{i=1}^{n}t_i^{\hat\gamma}}\right)^{\frac{1}{\hat\gamma}}
$$

Y sustituyendo en la segunda ecuación:

$$
\begin{array}{cc}
\frac{r}{\hat\gamma}+r\ln\left(\left(\frac{r}{\sum_{i=1}^{n}t_i^{\hat\gamma}}\right)^{\frac{1}{\hat \gamma}}\right)+\sum_{i=1}^{n}\delta_i\ln(t_i)&\\
-\left(\frac{r}{\sum_{i=1}^{n}t_i^{\hat \gamma}}\right)\left[\ln\left(\left(\frac{r}{\sum_{i=1}^{n}t_i^{\hat \gamma}}\right)^{\frac{1}{\hat \gamma}}\right)\sum_{i=1}^{n}t_i^{\hat \gamma}-\sum_{i=1}^{n}t_i^{\hat \gamma}\ln(t_i)\right]&=0
\end{array}
$$

La expresión anterior es una ecuación *no lineal* de $\hat \gamma$, cuya solución es únicamente mediante un método numérico. Una vez que se ha obtenido el valor $\hat \gamma$, éste se sustituye en $\left(\frac{r}{\sum_{i=1}^{n}t_i^{\hat \gamma}}\right)^{\frac{1}{\hat \gamma}}$ para así obtener, finalmente, el valor de $\hat \lambda$.

Ecuaciones *no lineales*, como hemos visto en el modelo *Weibull*, aparecen en la estimación de parámetros de las distribuciones *Log-Normal*, *Log-Logística* y *Gamma*; resulta que, al considerar datos con censura y truncamiento, las estimaciones se complican en los modelos paramétricos. No obstante, tenemos ayuda de las computadoras y software que nos permitirán realizar estimaciones adecuadas.

[^6.1]: De primera vista, pareciera que la segunda igualdad de la expresión anterior es incorrecta y que debería ser $\prod_{i=1}^{n}\left\{h(t_{i})\right\}^{\delta_{i}}\left\{\frac{S(t_{i})}{S(u_{i})}\right\}^{1-\delta_i}$ lo cual no es correcto. Se recomienda desarrollar la primera igualdad y relacionar lo necesario para obtener $h(t_i)$.

<!--chapter:end:06_Likehood.Rmd-->

# (PART) Estudio no paramétrico {-}

# Modelos No Paramétricos para la Función de Supervivencia

Los métodos estadísticos más utilizados en el análisis de supervivencia son los *No Paramétricos*. Debido a que sólo cuando se conoce la distribución que siguen los tiempos de falla, las estimaciones con métodos paramétricos será adecuada. La eficiencia de los métodos no paramétricos radica en que los datos no sigan una distribución teórica.

Puesto que nuestro interés es estimar $S(t)$, en los métodos no paramétricos las curvas de supervivencia, por lo general, se producen usando uno de dos métodos: el **análisis actuarial** o el **método límite-producto de Kaplan-Meier**.

Es importante mencionar que, cuando **no** hay datos censurados podemos estimar $S(t)$ de manera sencilla mediante la función empírica:

$$
\hat S(t) = \hat{\mathbb{P}}(T>t) = \frac{ \# t_{i}>t}{n}
$$

donde la muestra aleatoria es: $t_{(1)}\leq t_{(2)}\leq...\leq t_{(n)}$.

En este caso, la función será escalonada con decrementos $\frac{1}{n}$ si todas las observaciones son distintas, o con decrementos $\frac{d}{n}$ si hay $d$ tiempos de falla iguales a $t$. 

Los métodos que se presentan a continuación incluyen la percepción del censuramiento en los datos; quizá el alumno está familiarizado con alguno de ellos, pues se estudian en cursos previos.

## Método Actuarial (Tabla de Vida)

El análisis actuarial divide el tiempo en intervalos y calcula la supervivencia en cada intervalo. La longitud del intervalo depende de la frecuencia con que ocurre el suceso de interés.

Se asume que:

+ Todos los abandonos durante un intervalo dado ocurren aleatoriamente durante dicho intervalo.
+ Las personas que se retiran del estudio tienen un destino parecido a las que se quedan.
+ El periodo de tiempo durante el cual una persona entra en el estudio no tiene efecto en la respuesta.

Dividimos el eje del tiempo en $k+1$ intervalos $l_{j}=(a_{j-1},a_{j}]$. Entonces para cada elemento de una muestra aleatoria de tamaño $n$, se observa un tiempo de fallo $T$ o un valor censurado por la derecha $C$.

Definimos:

+ $n_{j}$: número de individuos en riesgo (vivos o no censurados) al tiempo $a_{j-1}$.
+ $d_{j}$: número de fallas en el intervalo $l_{j}$.
+ $c_{j}$: número de individuos que se censuran en el intervalo $l_{j}$.

El número de individuos sin falla al inicio de $l_{j}$ es $n_{j}$.

Suponga que la función de supervivencia para los tiempos de falla es $S(t) = \mathbb{P}(T>t)$. Entonces:

$$
S(a_{j}) = \mathbb{P}(T>a_{j}) = \mathbb{P}(T>a_{0})\mathbb{P}(T>a_{1}|T>a_{0})...\mathbb{P}(T>a_{j}|T>a_{j-1})
$$

Sea: 
 
+ $S_{j} = S(a_{j})$
+ $p_{j} = \mathbb{P}(T>a_{j}|T>a_{j-1}) =\frac{S_{j}}{S_{j-1}}$ (Sobrevivencia hasta $a_{j}$ después de haber sobrevivido hasta $a_{j-1}$)
+ $q_{j} = 1-p_{j} = \mathbb{P}(T\leq a_{j}|T>a_{j-1}) = \frac{S_{j-1}-S_{j}}{S_{j-1}}$ (No sobrevivir hasta $a_{j}$ después de haber sobrevivido hasta $a_{j-1}$)

Donde $S_{0} = 1$, $S_{k+1} = 0$, $q_{k+1} = 1$. Por lo tanto:

$$
S_{j} = p_{1}p_{2}...p_{j}
$$

El objetivo es estimar $S_j$ con base en la estimación de $p_j=1-q_j$.

Si en $l_{j}$ **no** hay observaciones censuradas, entonces estimamos $S_j$ por medio de: 

$$
\hat{q_{j}} = \frac{d_{j}}{n_{j}}
$$

Por otro lado, si en $l_{j}$ **hay** observaciones censuradas, y suponiendo que las censuras se distribuyen uniformemente, entonces $S_j$ se puede obtener mediante:

$$
\hat{q_{j}} = \frac{d_{j}}{n_{j}-\frac{c_{j}}{2}}
$$

De modo que, para este caso, se tiene:

$$
\hat S_j=\prod_{i=1}^{j}\left(1-\frac{d_{i}}{n_{i}-\frac{c_{i}}{2}}\right)
$$

#### Ejemplo {-}

El siguiente ejemplo es tomado del libro [@collett2015modelling], ejemplo 1.3 :

Supervivencia de pacientes con myeloma múltiple.

Myeloma múltiple es una enfermedad caracterizada por la acumulación múltiple de células plasmáticas anormales, un tipo de células blancas de la sangre, en la médula ósea. La proliferación de las células plasmáticas anormales dentro de los huesos causa dolor y la destrucción del tejido óseo. El objetivo de un estudio realizado en el Centro Médico de la Universidad del Oeste de Virginia, USA, fue examinar la asociación entre los valores de ciertas variables explicativas(covariables) y el tiempo de supervivencia de los pacientes. En el estudio, el tiempo de supervivencia fue medido en meses, desde el diagnóstico hasta la muerte por myeloma múltiple.

La siguiente tabla muestra un **fragmento** de los resultados obtenidos en el estudio. En ésta se relaciona a un total de 48 pacientes, todos ellos estaban entre los 50 y 80 años. Algunos de estos pacientes no habían muerto durante el tiempo que el estudio fue completado, por lo que estos individuos contribuyeron con tiempos censurados por la derecha. La codificación del estatus de supervivencia de un individuo en la tabla es codificado con un $0$ si la observación es censurada y $1$ si fue muerte por myeloma.

```{r}
#tabla para mostrar
Ej1 <- data_frame("Patient\nnumber" = 1:20, 
           "Survival\ntime" = c(13,52,6,40,10,7,66,10,10,14,16,4,65,5,11,10,15,5,76,56),
           Status = c(1,0,1,1,1,0,1,0,rep(1,6),0,1,0,1,0,0),
           Age = c(66,66,53,69,65,57,52,60,70,70,68,50,59,60,66,51,55,67,60,66),
           Sex = c(1,1,2,1,1,2,rep(1,5),2,1,1,2,2,1,2,1,1),
           Bun =c(25,13,15,10,20,12,21,41,37,40,39,172,28,13,25,12,14,26,12,18),
           Ca = c(10,11,13,10,10,8,10,9,12,11,10,9,9,10,9,9,9,8,12,11),
           Hb = c(14.6,12,11.4,10.2,13.2,9.9,12.8,14,7.5,10.6,11.2,10.1,6.6,9.7,8.8,9.6,13,10.4,14,12.5),
           Pcells = c(18,100,33,30,66,45,11,70,47,27,41,46,66,25,23,80,8,49,9,90),
           Protein = c(1,0,1,1,0,0,1,1,0,0,0,1,rep(0,8)))
Ej1%>% kable(booktabs = T, align=rep('c')) %>% kable_styling(bootstrap_options = c("striped", "responsive", "condensed"), full_width = F)

#tabla con que se trabaja los datos
Ej1 <- data_frame(Patient_number = 1:48, 
           Survival_time = c(13,52,6,40,10,7,66,10,10,14,16,4,65,5,11,10,15,5,76,56,88,24,51,4,40,8,18,5,16,50,40,1,36,5,10,91,18,1,18,6,1,23,15,18,12,12,17,3),
           Status = c(1,0,1,1,1,0,1,0,rep(1,6),0,1,0,1,0,0,rep(1,4),0,rep(1,11),0,1,0,rep(1,5),0,1,1,0),
           Age = c(66,66,53,69,65,57,52,60,70,70,68,50,59,60,66,51,55,67,60,66,63,67,60,74,72,55,51,70,53,74,70,67,63,77,61,58,69,57,59,61,75,56,62,60,71,60,65,59),
           Sex = c(1,1,2,1,1,2,rep(1,5),2,1,1,2,2,1,2,rep(1,4),2,rep(1,4),2,1,1,2,rep(1,4),2,2,1,2,2,1,rep(2,6),1),
           Bun =c(25,13,15,10,20,12,21,41,37,40,39,172,28,13,25,12,14,26,12,18,21,10,10,48,57,53,12,130,17,37,14,165,40,23,13,27,21,20,21,11,56,20,21,18,46,6,28,90),
           Ca = c(14.6,12.0,11.4,10.2,13.2,9.9,12.8,14,7.5,10.6,11.2,10.1,6.6,9.7,8.8,9.6,13,10.4,14,12.5,14,12.4,10.1,6.5,12.8,8.2,14.4,10.2,10,7.7,5,9.4,11,9,14,11,10.8,5.1,13,5.1,11.3,14.6,8.8,7.5,4.9,5.5,7.5,10.2),
           Hb = c(14.6,12,11.4,10.2,13.2,9.9,12.8,14,7.5,10.6,11.2,10.1,6.6,9.7,8.8,9.6,13,10.4,14,12.5,12,12.4,10.1,6.5,12.8,8.2,14.4,10.2,10,7.7,5,9.4,11,9,14,11,10.8,5.1,13,5.1,11.3,14.6,8.8,7.5,4.9,5.5,7.5,10.2),
           Pcells = c(18,100,33,30,66,45,11,70,47,27,41,46,66,25,23,80,8,49,9,90,42,44,45,54,28,55,100,23,28,11,22,90,16,29,19,26,33,100,100,100,18,3,5,85,62,25,8,6),
           Protein = c(1,0,1,1,0,0,1,1,0,0,0,1,rep(0,8),1,0,1,0,1,rep(0,4),1,0,0,1,0,0,1,0,1,rep(0,5),1,0,0,0,1))
```

Ahora bien, se busca estimar $S(t)$ mediante la construcción de la tabla de vida. La información registrada en otras variables explicativas será ignorada.

Se consideran los intervalos de tiempo, para cada uno se calcula el número de pacientes que fallecieron $d_{j}$,el número de datos censurados $c_{j}$, el número en riesgo de muerte al inicio de cada uno de estos intervalos $n_{j}$, y el número ajustado en riesgo $n_{j}^{*}=n_{j}-\frac{c_{j}}{2}$ (dado que hay datos censurados). Finalmente, la probabilidad de supervivencia en cada intervalo es estimada(multiplicando cada $p_j$).

Los cálculos son presentados a continuación:

```{r}
Ej1$Interval <- Ej1$Survival_time
Ej1$Interval[Ej1$Interval<12] <- 1
Ej1$Interval[Ej1$Interval>=12 & Ej1$Interval<24] <- 2
Ej1$Interval[Ej1$Interval>=24 & Ej1$Interval<36] <- 3
Ej1$Interval[Ej1$Interval>=36 & Ej1$Interval<48] <- 4
Ej1$Interval[Ej1$Interval>=48 & Ej1$Interval<60] <- 5
Ej1$Interval[Ej1$Interval>=60] <- 6

Ej4 <- Ej1 %>% 
  group_by(Interval) %>%
  mutate(d_j = sum(Status)) %>% 
  ungroup() %>% 
  mutate(Status = 1-Status) %>% 
  group_by(Interval) %>% 
  mutate(C_j = sum(Status)) %>% 
  group_by(Interval,d_j,C_j) %>% 
  summarise(n_j = n()) %>%
  ungroup() %>% 
  mutate(n_j = suma_a_saltos(n_j)) %>%
  mutate(n_j_p = n_j-C_j/2) %>% 
  mutate(p_j = (n_j_p-d_j)/n_j_p) %>% 
  mutate("S(t)" = cumprod(p_j), "Time period" = c("0-", "12-", "24-", "36-", "48-", "60-")) %>%
  select(Interval, "Time period", d_j, C_j, n_j, n_j_p, p_j, "S(t)")

#Se hace una copia para evitar problemas con la gráfica
Ej4_1 <- Ej4
colnames(Ej4_1)[3:8] <- c("$d_j$", "$c_j$", "$n_j$", "$n_j^{*}$", "$p_j$", "$S(t)$")

Ej4_1 %>% kable(escape = FALSE, booktabs = T, align=rep('c')) %>% kable_styling(bootstrap_options = "striped", full_width = F)
```

Y la curva de supervivencia es la dada en la figura \@ref(fig:survival-actuar-example):

```{r survival-actuar-example, fig.cap='Supervivencia estimada para los pacientes con myeloma múltiple con el método actuarial'}
Ej4 %>% 
  mutate(Time = c(0,12,24,36,48,60)) %>% 
  rename(S="S(t)") %>% 
  ggplot(aes(y = S, x = Time)) + 
  geom_step() + 
  ggtitle("Curva de Supervivencia. Tabla de Vida.") +
  labs(x = "Tiempo de supervivencia", y = "Supervivencia estimada") +
  general_theme
```

## Estimador Producto-Límite (Kaplan-Meier)

El estimador producto-límite fue propuesto por Kaplan y Meier en 1958 como el estimador máximo-verosímil de la función de supervivencia.

El método de Kaplan-Meier calcula la supervivencia cada vez que un paciente muere. Da proporciones exactas de supervivencia debido a que utiliza tiempos de supervivencia precisos.

La característica distintiva del análisis con este método, es que la proporción acumulada que sobrevive se calcula para el tiempo de supervivencia individual de cada paciente, en contraste con la agrupación de los tiempos de supervivencia en intervalos hechos en la tabla de vida. Por esta razón es especialmente útil para estudios que utilizan un número pequeño de pacientes.

Este método asume que:

+ Las personas que se retiran del estudio tienen un destino parecido a las que se quedan.
+ El periodo de tiempo durante el cual una persona entra en el estudio no tiene efecto independiente en la respuesta.

### Construcción del Estimador K-M

Es natural pensar a $T$ como una variable aleatoria continua, y por tanto, teóricamente no es posible tener observaciones iguales. No obstante, en la práctica los tiempos de supervivencia son medidos en escalas como: días, meses, años, etcétera; por lo que, hay posibilidad de tener observaciones repetidas. Por esta razón conviene modelar a $T$ como una variable aleatoria discreta. La idea del estimador *K-M* es la siguiente:

Sea $T_{1}, T_{2},...,T_{n}$ una m.a. de una población discreta con soporte en $\{u_{1}, u_{2},...\}$.

La muestra observada de $T$ se puede representar como $(t_{i},\delta_{i})$ para $i=1,2,...,n$ donde:

$$
\delta_{i} = \left\{
\begin{array}{ll}
0 & \mbox{si }  t_i \ es \ censurado\\
1 & \mbox{si }  t_{i} \ no \ es \ censurado
\end{array}
\right.
$$
Entonces la función de verosimilitud será:

$$ 
\mathscr{L} = \prod^{n}_{i=1}f(t_{i})^{\delta_{i}}S(t_{i})^{1-\delta_{i}} 
$$

Desarrollando la expresión anterior tenemos 

$$
\mathscr{L} =\prod^{n}_{i=1}(h(u_{k})S(u_{k-1})\mathbb{1}_{t_{i}=u_{k}})^{\delta_{i}} (S(u_{k})\mathbb{1}_{k=max\{j:u_{j}\leq t_i\}})^{1-\delta_{i}}
$$

Sea 

$$
\begin{split}
 & d_{k} = \sum_{i=1}^{n}\mathbb{1}_{(t_{i}=u_{k},\delta_{i}=1)} \mbox{  (numero de tiempos de fallo iguales a }u_{k}) \\
 & n_{k} = \sum_{i=1}^{n}\mathbb{1}_{(t_{i}\geq{u_{k}})} \mbox{ (numero de individuos en riesgo al tiempo } u_{k})
\end{split}
$$

$$
\Longrightarrow \mathscr{L} = \prod_{k} (h(u_k))^{d_k}(1-h(u_k))^{n_k-d_k}
$$

Ahora maximizamos la función de verosimilitud para $h(u_k)$:

$$
\ln (\mathscr{L}) = \sum_{k}\{d_{k} \ln(h(u_{k}))+(n_{k}-d_{k}) \ln(1-h(u_{k}))\} 
$$

$$
\Longrightarrow \frac{\partial \ln (\mathscr{L})}{\partial h(u_{k})} = \frac{d_{k}}{h(u_{k})}-\frac{(n_{k}-d_{k})}{(1-h(u_{k}))} = 0
$$

despejando $h(u_k)$ se tiene

$$
\therefore \hat{h}(u_{k}) = \frac{d_{k}}{n_{k}}
$$

Dado que los estimadores máximo-verosímiles cumplen con el principio de invarianza, y ocupando que $S(t)=\prod_{k:u_{k}\leq t}(1-h(u_{k}))$ (visto anteriormente) tenemos:

$$
\hat S(t)=\prod_{k:u_{k}\leq t}\left(1-\frac{d_k}{n_k}\right)
$$

Y es así es como se deriva el estimador *K-M*.

**Proposición:** $\mathbb{E}[\hat{h}(u_k)] =h(u_k)$ (Insesgamiento).

#### Ejemplo {-}

Se obtuvieron los tiempos de remisión de 20 pacientes con osteosarcoma, a los que se trataba con 3 meses de quimioterapia después de amputación.

+ 11 pacientes recayeron a los 6, 8, 10, 11, 12, 13, 13, 22, 32, 34 y 36 meses.
+ 8 pacientes se retiraron vivos al final del estudio contribuyendo 3, 7, 7, 11, 14, 16, 20 y 20 meses de observación, sin haber sufrido recaídas.
+ Un paciente rehusó continuar la terapia a los 11 meses y se retiró del estudio libre de enfermedad.

La siguiente tabla muestra la forma de estimar $S(t)$ por el método *K-M*: 

```{r}
datos <- c(6,8,10,11,12,13,13,22,32,34,36,3,7,7,11,14,16,20,20,11)
censura <- c(rep(1,11),rep(0,9))
su <- Surv(datos, censura)
ajuste <- survfit(su~1,type="kaplan-meier")
tabla <- summary(ajuste)


Ej2 <- data_frame(time = tabla$time, dk =tabla$n.event , nk =tabla$n.risk) %>%
  mutate(ck =tabla$n.censor, "1-dk/nk" = 1-(dk/nk), "S(t)" = tabla$surv) 
Ej2_1 <- Ej2
colnames(Ej2_1)[-1] <- c("$d_j$", "$n_k$", "$c_k$", "$1-\\frac{d_k}{n_k}$", "$S(t)$")
Ej2_1 %>% kable(escape = FALSE, booktabs = T, align=rep('c')) %>% 
  kable_styling(bootstrap_options = "striped", full_width = F)
```

Y la gráfica de $\hat S(t)$ es:

```{r}
Ej2 %>% rename(S = "S(t)") %>% 
  ggplot(aes(x = time, y= S)) + 
  geom_step() + 
  ggtitle("Curva Kaplan-Meier.") +
  labs(x = "Tiempo en meses", y = "Supervivencia estimada") + 
  general_theme
```

#### Ejercicio {-}

Suponga que disponemos de los datos de supervivencia de 10 pacientes que han sido aleatoriamente asignados a los tratamientos A y B.

+ A: 3, 5, 7, 9+, 18
+ B: 12, 19, 20, 20+, 33+

Construya la función de supervivencia para cada tratamiento y grafíquelas. ¿Qué se puede decir de los tratamientos a partir de las gráficas?

<!--chapter:end:07_NoParametric.Rmd-->

# Algunas Estimaciones sobre Modelos No Paramétricos

Cuando se emplean los modelos no paramétricos, es necesario hacer inferencia más allá de la estimación puntual. Para tal propósito, conocer la varianza de algunos estimadores de interés, resulta de gran ayuda.

## Estimación de la Varianza para el Estimador de $S(t)$

### Tabla de Vida

Para la tabla de vida se tienen los siguientes resultados:

$$
\begin{array}{ll}
\hat{q_j} = \frac{d_{j}}{n_{j}-\frac{c_{j}}{2}} &  \hat{S_{j}}=\prod_{i=1}^{j}\left(1-\frac{d_{i}}{n_{i}-\frac{c_{i}}{2}}\right)\\
\end{array}
$$

Entonces un estimador de la varianza para $\hat{S_j}$ es: 

$$
 \hat{Var}(\hat{S}_{j}) = \hat{S}_{j}^2\sum_{i = 1}^{j}\frac{\hat{q_i}}{\hat{p_i}(n_{i}-\frac{c_{i}}{2})}
$$

Si deseamos obtener intervalos de confianza puntuales para $S(t)$, podemos partir de la distribución asintótica de $\hat{S_j}$:

$$
\hat{S}_j \sim N(S_{j}, \hat{Var}(\hat{S_{j}}))
$$

De donde, un intervalo de confianza para $S(t_j)$ al $(1-\alpha)*100\%$ es:

$$
\hat S_j \pm Z_{1-\frac{\alpha}{2}} \sqrt{\hat{Var}(\hat S_j)}
$$

### Kaplan-Meier

Partiendo de que

$$
\hat{S}(t) = \prod_{k:u_k \leq t}(1-h_{k})
$$

Si aplicamos $\ln$ tenemos:

$$
\ln(\hat{S(t)}) = \sum_{k:u_k \leq t} \ln(1-h_k)
$$

$$
\Longrightarrow Var(\ln(\hat{S}(t))) = \sum_{k:u_k \leq t} Var(\ln(1-h_k))
$$

Desarrollando con series de Taylor (método Delta) se obtiene:

$$
Var(\hat{S}(t)) = \hat{S}^2(t)\sum_{k:u_k \leq t}\frac{Var(\hat{h}_k)}{(1-\hat{h}_{k})^2}
$$

Uno de los **estimadores** más comunes para $Var(\hat{S}(t))$ es el **estimador de Greenwood**; éste supone que el número de individuos que sobreviven a lo largo del intervalo que empieza en $t_j$ tiene una distribución *Binomial* con parámetros $n_j$ y $p_j$ ($p_j$ es la verdadera probabilidad de supervivencia a lo largo del intervalo). De manera que, el estimador Greenwood es: 

$$
\hat{Var}(\hat{S}(t)) \approx \hat{S}^2(t) \sum_{j:t_{j}\leq t}\frac{d_{j}}{n_{j}(n_{j}-d_{j})}
$$

+ El estimador del error estándar será: $\sqrt{\hat{Var}(\hat{S}(t))}$.

+ Cuando $n\rightarrow\infty$, $\hat{S}(t)$ tiene una distribución normal: $\hat{S}(t)\sim N(S(t), Var(\hat{S}(t)))$.

+ El intervalo puntual al $(1-\alpha)*100\%$ de confianza para $S(t_{0})$ será: $\hat{S}(t_{0}) \pm Z_{1-\alpha/2} \sqrt{\hat{Var}(\hat{S}(t_0))}$[^8.1].

Para este último punto, pueden existir ocasiones en las que el intervalo de confianza se encuentre fuera del rango $[0,1]$, por lo que existen diferentes aproximaciones para resolver dicho problema. Una de ellas es mejorando la aproximación a la distribución normal (ya que se menciono previamente que : $\hat{S}(t)\sim N(S(t), Var(\hat{S}(t)))$) utilizando la transformación $log-log$, obteniendo así la siguiente expresión:

$$
\hat{S}(t_{0}) \pm e^{Z_{1-\alpha/2} \frac{\sqrt{\hat{Var}(\hat{S}(t_0))}}{\hat{S}(t_{0})\ln(\hat{S}(t_{0}))}}
$$

Otra alternativa es utilizando una transformación logarítmica para obtener lo siguiente

$$
\exp\left(\ln(\hat{S}(t_{0})) \pm Z_{1-\alpha/2} \frac{\sqrt{\hat{Var}(\hat{S}(t_0))}}{\hat{S}(t_{0})}\right)
$$

#### Ejercicio {-}

Un estudio consistió en medir el tiempo(en meses) en que los pacientes desarrollaron un cierto tipo de tumor. Los resultados que se obtuvieron fueron: 

$$
10,13^+,18^+,19,23^+,30,36,38^+,54^+,56^+,59,75,93,97,104^+,107,107^+,107^+
$$

La siguiente tabla muestra  $\hat S(t)$ por el método de *K-M*, además de los intervalos de confianza puntuales utilizando el estimador de *Greenwood*:
  
```{r}
datos <- c(10,13,18,19,23,30,36,38,54,56,59,75,93,97,104,107,107,107)
censura <- c(1,0,0,1,0,1,1,0,0,0,1,1,1,1,0,1,0,0)
su <- Surv(datos, censura)
ajuste <- survfit(su~1,type="kaplan-meier",conf.type="plain")
tabla <- summary(ajuste)

Ej2 <- data_frame(time = tabla$time, dk =tabla$n.event , nk =tabla$n.risk) %>%
  mutate(ck =tabla$n.censor, "S(t)" = tabla$surv,
         "std error"=tabla$std.err,"Lower_95%"=tabla$lower,"Upper_95%"=tabla$upper) 
Ej2_1 <- Ej2
colnames(Ej2_1)[2:5] <- c("$d_k$", "$n_k$", "$c_k$", "$S(t)$")
colnames(Ej2_1)[7:8] <- c("Lower\\_95\\%", "Upper\\_95\\%")
Ej2_1 %>% kable(escape = FALSE, booktabs = T, align=rep('c')) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

La gráfica correspondiente es:

```{r}
Ej2 %>% add_row(time = 0, `S(t)` = 1,`std error` = 1, `Lower_95%` = 1, .before = 1)%>% 
  rename(S = "S(t)", li = "Lower_95%", up = "Upper_95%") %>% 
  ggplot(aes(x = time, y= S)) + 
  geom_step() + 
  geom_step(aes(y = li), linetype = "dashed")+
  geom_step(aes(y = up), linetype = "dashed")+
  ggtitle("Gráfica Kaplan-Meier.")+
  scale_x_continuous(breaks = seq(0,100, 20))+
  labs(x = "Tiempo", y = "Supervivencia estimada") + 
  general_theme
```

## Estimadores de la Función de Riesgo Acumulada

Recordemos que:

$$
H(t)=-log(S(t)) 
$$

Entonces podemos estimar $H(t)$ de una manera sencilla ($\hat{S}(t)$ es obtenido por *K-M*):

$$
\hat{H_1}(t) = -log(\hat{S}(t))
$$

No obstante, una alternativa para conocer $H(t)$ es utilizar el **estimador Nelson-Aalen**. Este estimador resulta útil primordialmente en el análisis de datos para la selección entre modelos paramétricos para el tiempo de fallo $T$, además proporciona un estimador para $h(t)$. El estimador *Nelson-Aalen* asume que $H(t)$ es la suma de riesgos, esto es:

$$
H(t)=\sum_{j:u_{j}\leq t} h_j
$$

Entonces el estimador de $H(t)$ será:

$$
\hat{H_2}(t)=\sum_{j:u_{j}\leq t} \hat h_j=\sum_{j:u_{j}\leq t}\frac{d_j}{n_j}
$$


Observe que si tomamos $\hat H_2(t)$, podemos estimar de otra manera a $S(t)$. Es decir, $S(t)$, usando **Nelson-Aalen**, se obtiene el estimador _**Fleming-Harrington**_, el cual es:

$$
\hat{S_2}(t) = exp\{-\hat{H_2}(t)\} = exp\left\{-\sum_{j:u_{j}\leq t}\frac{d_j}{n_j}\right\}
$$

Un estimador de la varianza de $\hat{H_2}(t)$ es:

$$
\hat{Var}(\hat{H_2}(t)) = \sum_{j:t_{j}\leq t}\frac{d_j}{n_{j}^{2}}
$$

Y el intervalo de confianza puntual al $(1-\alpha)*100\%$ para ${H_2}(t_0)$ es:
  
$$
\hat{H_2}(t_{0}) \pm Z_{1-\alpha/2} \frac{\sqrt{\hat{Var}\{\hat{H_2}(t)\}}}{\hat{H_2}(t_{0})}
$$

#### Ejemplo {-}

Siguiendo con el ejemplo anterior, que mide el tiempo (en meses) en que los pacientes desarrollaron un cierto tipo de tumor. 

La tabla muestra $\hat S(t)$ por el método de *K-M*, entonces podemos calcular $\hat {H}_1(t)=-log(\hat S(t))$. Y por otro lado usar el estimador Nelson-Aalen para obtener $\hat{H}_2(t)$.

```{r}
datos <- c(10,13,18,19,23,30,36,38,54,56,59,75,93,97,104,107,107,107)
censura <- c(1,0,0,1,0,1,1,0,0,0,1,1,1,1,0,1,0,0)
su <- Surv(datos, censura)
ajuste <- survfit(su~1,type="kaplan-meier",conf.type="plain")
tabla <- summary(ajuste)

Ej2 <- data_frame(time = tabla$time, dk =tabla$n.event , nk =tabla$n.risk) %>%
  mutate(ck =tabla$n.censor, "S(t)" = tabla$surv,
         "H(t)"=-log(tabla$surv), "H_2(t)" = cumsum(tabla$n.event/tabla$n.risk)) 
Ej2_1 <- Ej2
colnames(Ej2_1)[2:7] <- c("$d_k$", "$n_k$", "$c_k$", "$S(t)$","$H_1(t)$", "$H_2(t)$")
Ej2_1 %>% kable(escape = FALSE, booktabs = T, align=rep('c')) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

## Estimación Puntual de la Media

Puede ser de interés estudiar algunos parámetros poblacionales que dependen de la función de supervivencia. Por ejemplo: la media, la mediana y cualquier cuantil o percentil.

Hemos visto en la sección \@ref(media) que:

$$
\mu = \int_{0}^{\infty}S(t)dt
$$

Entonces podemos reemplazar $S(t)$ con el estimador de $\hat{S}(t)$(obtenido por *K-M*), por lo que:

$$
\hat{\mu}=\int_{0}^{\infty}\hat{S}(t)dt
$$

**Observación:** El estimador será apropiado si la observación más grande del conjunto de datos es un tiempo de falla y **NO** una observación censurada.

Si la última observación(la más grande) es una observación censurada, entonces $\hat{\mu}$ se calcula como:

$$
\hat{\mu}_{\tau} =\int_{0}^{\tau}\hat{S}(t)dt
$$

Donde $\tau$ es el valor que determina el tiempo más grande al que una persona puede sobrevivir.

Un estimador de la varianza de $\hat{\mu}_{\tau}$ con $t_{1}, t_{2},...,t_{k}$ tiempos de fallo observados, es: 

$$
\hat{Var}(\hat{\mu_\tau}) = \sum_{i = 1}^{k}\left\{\int_{t_i}^{\tau}\hat{S}(t)dt\right\}^2 \cdot \frac{d_{i}}{n_{i}(n_{i}-d_{i})}
$$

El intervalo al $(1-\alpha)100\%$ de confianza para $\mu_\tau$ es:

$$
\hat\mu_{\tau} \pm Z_{1-\alpha/2}\sqrt{\hat{Var}(\hat\mu_\tau)}
$$

**NOTA:** Es importante que, cuando se esté calculando la media de supervivencia $\hat\mu_{\tau}$, se verifique que el último valor no sea censurado y se observe en qué intervalo se está calculando la media.

## Estimación de Cuantiles

Recordemos que los cuantiles de orden $p$, $t_p$, es el mínimo valor $t$ tal que $S(t)\leq 1-p$. Usando el estimador $\hat{S}(t)$ obtenido por *K-M*, tenemos:

$$
\hat{t}_p = inf\{t:\hat{S}(t)\leq 1-p\}
$$

Por lo que, si deseamos calcular la **mediana estimada**:

$$
\hat{t}_{0.5} = inf\{t:\hat{S}(t)\leq 0.5\}
$$

## Bandas de Confianza para la Función de Supervivencia

Deseamos encontrar dos v.a. $L(t)$ y $U(t)$ tales que:

$$
\begin{array}{ll}
\mathbb{P}(L(t)\leq S(t)\leq U(t)) = 1-\alpha & \forall t_{L}\leq t\leq t_{U}\\
\end{array}
$$

Entonces $[L(t), U(t)]$ serán las bandas al $(1-\alpha)*100\%$ de confianza de $S(t)$. Puede usted decir ¿cuál es la diferencia entre *bandas de confianza* e *intervalos de confianza puntuales*?

Hay dos métodos de aproximación para las bandas de confianza. La primera aproximación fue propuesta por *Nair* [@nair1984confidence] y esencialmente proporciona límites de confianza que son proporcionales a los intervalos de confianza puntuales, estas bandas son llamadas *bandas de probabilidad iguales* o *bandas EP*[^8.2]. Caso contrario, la segunda aproximación, propuesta por [*Hall* y *Wellner*](http://www.ressources-actuarielles.net/EXT/ISFA/1226.nsf/0/b163cbaba7cf2db9c125776b004d3573/%24FILE/Hall_Wellner_1980.pdf)[^8.3] [@hall1980confidence], establece bandas no proporcionales a los intervalos de confianza puntuales.

Nuestro interés es obtener las bandas de confianza para $S(t)$; afortunadamente hoy en día se cuenta con software que nos ayuda en dicha tarea, específicamente en **R** es sencillo obtenerlo.

## Diagnóstico para el Uso de Modelos Paramétricos

Si existe la necesidad de encontrar un modelo paramétrico que ajuste "bien" a los datos, se pueden emplear algunos métodos gráficos que nos den algunos *indicios* sobre la posible *distribución* de los datos. Tales indicios pueden ser proporcionados por los métodos no paramétricos.

### Gráficas de las Funciones de Supervivencia

Se conoce la función de supervivencia paramétrica $S(t ;\theta)$ y se tiene un estimador $\hat \theta$. Si el modelo paramétrico es *adecuado* entonces $S(t ;\hat {\theta})$ y $\hat S(t)$(estimada por *K-M*) deben ser *similares*.

#### Ejemplo {-}

Se tienen los siguientes tiempos de supervivencia:

$$
8,5,10^+,1,3,18,22,15,25^+,19
$$

Se desea saber si estos datos ajustan a un modelo *exponencial* con $\lambda =0.06$. Realizamos las gráficas de supervivencia:

```{r}
datos <- c(8,5,10,1,3,18,22,15,25,19)
censura <- c(1,1,0,1,1,1,1,1,0,1)
su <- Surv(datos, censura)
ajuste <- survfit(su~1,type="kaplan-meier")
tabla <- summary(ajuste)

tibble(time = tabla$time, S = tabla$surv) %>% 
  add_row(time = c(0, 25), S = c(1, 0.12), .before = 1) %>% 
  ggplot(aes(x = time, y= S)) + 
  geom_step(aes(color = "1"), key_glyph='rect') + 
  geom_line(data = tibble(x = seq(0,25,0.1), y = 1-pexp(x,0.06)),
            aes(x = x, y = y, color = "2"), key_glyph='rect') +
  ggtitle("Curva Kaplan-Meier.") +
  labs(x = "Tiempo", y = "Supervivencia") + 
  ggtitle("Gráficas de Supervivencia para Diagnóstico") +
  general_theme +
  theme(legend.key = element_rect(colour = 'gray98'),
        legend.position = c(.9, .8), 
        legend.title = element_blank(),
        legend.background = element_blank(),
        legend.text.align = 0,
        legend.direction = "vertical",
        legend.spacing.x = unit(.2, 'cm'),
        legend.key.size = unit(.4, "cm"))+
  scale_color_manual(values = c("1" = "black", "2" = "red"),
                     labels = unname(TeX(c("$\\hat{S}(t)$",
                                           "$S(t, \\hat{\\theta})$"))))
```

De acuerdo a la gráfica anterior, ¿Existe algún indicio de que los datos siguen una distribución exponencial con $\lambda =0.06$?

### Gráfica $P-P$

Si el modelo paramétrico es adecuado entonces los puntos:

$$
\left(S(t_j ;\hat{\theta}),\hat S(t_j)\right)
$$

Deberán caer en la recta identidad ($\hat S(t_j)$ es estimada por *K-M*). Es llamada *gráfica $P-P$* pues se gráfica *Probabilidad vs Probabilidad*.

#### Ejemplo {-}

Tomando los datos del ejemplo anterior, queremos ver si los datos se distribuyen posiblemente exponencial con $\lambda =0.06$. Si hacemos la gráfica *P-P* se tiene:

```{r}
datos <- c(8,5,10,1,3,18,22,15,25,19)
censura <- c(1,1,0,1,1,1,1,1,0,1)
su <- Surv(datos, censura)
ajuste <- survfit(su~1,type="kaplan-meier")

tibble(x = seq(0,1,0.1)) %>% 
  ggplot(aes(x = x, y = x)) + 
  general_theme+
  geom_line()+
  geom_point(data = tibble(tiempo = summary(ajuste)$time, 
                           y = 1-pexp(tiempo,0.06), superv = summary(ajuste)$surv),
    aes(x = y, y = superv), color = "blue", shape = 1, size = 2)+
  ggtitle("Gráfica P-P") +
  labs(x = TeX("$S(t, \\hat{\\theta)}$"), y = TeX("$\\hat{S}(t)$"))
```

De acuerdo a la gráfica *$P-P$*, ¿Es el modelo exponencial con $\lambda=0.06$ adecuado a los datos?

### Gráfica $Q-Q$

La *gráfica $Q-Q$* consiste en graficar diversos cuantiles de los **datos** *vs* diversos cuantiles del modelo paramétrico propuesto. Si el modelo teórico propuesto es "adecuado" a los datos entonces la gráfica será cercana a la función identidad.

A continuación se muestra un ejemplo de la gráfica $Q-Q$:

```{r}
set.seed(120)
tibble(y = rnorm(20)) %>% 
  ggplot(aes(sample = y)) + stat_qq(color = "red", shape = 1, size = 2) + 
  # stat_qq_line()+
  geom_line(data = tibble (x = c(-2, 2), y = c(-2, 2)), aes(x = x, y = y))+
  ggtitle("Gráfica Q-Q")+
  labs(x = "Cuantiles teóricos", y = "Cuantiles de la muestra")+
  general_theme
```


### Linearización de la Función de Supervivencia

Cuando tenemos un modelo paramétrico $S(t;\theta)$ pero no conocemos $\hat{\theta}$ podemos hacer *linearización de la función de supervivencia*. Es decir, si existen $g_1$ y $g_2$ tales que $g_1\{S(t;\theta)\}$ es una función *lineal* de $g_2(t)$ entonces podemos graficar $g_1(\hat{S}(t))$ *vs* $g_2(t)$. Y si la familia paramétrica es adecuada, la gráfica se aproxima a una linea recta. Para este método gráfico se utiliza el estimador **Nelson-Aalen** para $\hat S(t)$.

#### Modelo Exponencial {-}

Tenemos que:

$$
S(t)=e^{-\lambda t}
$$

$$
\Longrightarrow log\{S(t)\}=-\lambda t  
$$

De manera que $g_1=log\{S(t)\}$ y $g_2=t$. Entonces debemos graficar $log(\hat S(t))$ *vs* $t$, y si los datos se ajustan a un modelo exponencial, dicha gráfica debe ser aproximadamente una linea recta con pendiente $-\lambda$. 

#### Ejemplo {-}

Consideremos los datos: $8,5,10^+,1,3,18,22,15,25^+,19$, veamos si se pueden ajustar posiblemente a un modelo exponencial a través de la gráfica de linearización. Entonces tenemos:

```{r}
datos <- c(8,5,10,1,3,18,22,15,25,19)
censura <- c(1,1,0,1,1,1,1,1,0,1)
su <- Surv(datos, censura)
ajuste <- survfit(su~1,type="kaplan-meier")

tibble(tiempo = summary(ajuste)$time, superv = log(summary(ajuste)$surv)) %>% ggplot(aes(x = tiempo, y = superv)) + 
  geom_line() +
  labs(x = TeX("$t$"), y = "Log Supervivencia Estimada") + 
  ggtitle("Diagnóstico Modelo Exponencial") +
  general_theme
```

¿Qué puede decir a partir de la gráfica anterior?, ¿Puede asumirse que los datos se ajustan a un modelo exponencial?

#### Modelo Weibull {-}

Para el modelo Weibull tenemos que:

$$
S(t)=e^{-(\lambda t)^{\gamma}}
$$

$$
\Longrightarrow -log\{S(t)\}=(\lambda t)^{\gamma}
$$

$$
\Longrightarrow log\{-log\{S(t)\}\}=\gamma (log(\lambda)+log(t))
$$

Entonces $g_1=log\{-log\{S(t)\}\}$ y $g_2=log(t)$. Por lo que debemos graficar $log\{-log\{\hat S(t)\}\}$ *vs* $log(t)$, y si los datos se ajustan a un modelo Weibull, la gráfica debe ser aproximadamente una linea recta con intercepto $\gamma log(\lambda)$ y pendiente $\gamma$.


#### Modelo Log-Logístico {-}

La función de supervivencia es:

$$
S(t)=(1+\lambda t^{\alpha})^{-1}
$$

$$
\Longrightarrow -log\{S(t)\}=log(1+\lambda t^{\alpha})
$$

$$
\Longrightarrow log\{exp\{-log\{S(t)\}\}-1\}=log(\lambda)+\alpha log(t)
$$

La gráfica de diagnóstico es: $log\{exp\{-log\{\hat S(t)\}\}-1\}$ *vs* $log(t)$. Si el modelo Log-Logístico es adecuado a los datos, entonces la gráfica es aproximadamente una linea recta con intercepto $log(\lambda)$ y pendiente $\alpha$.


#### Modelo Log-Normal {-}

Para este modelo, la gráfica que debemos emplear para el diagnóstico es $\Phi^{-1}[1-exp(-log(\hat S(t)))]$ *vs* $log(t)$, donde $\Phi^{-1}$ son los cuantiles de una *Normal estándar*. Una linea recta(aproximadamente) indica una posible distribución Log-Normal en los datos.

Los métodos gráficos que hemos visto son una herramienta que proporcionan indicios sobre la posible distribución de los datos(si nuestro interés es encontrar un modelo paramétrico). Evidentemente una gráfica no **demuestra nada** por lo que tendríamos que realizar pruebas formales de **bondad de ajuste** (pruebas que consideren la censura y/o truncamiento).

[^8.1]: Posiblemente al realizar las cuentas, como en el ejemplo que se encuentra en esta sub sección, se obtengan valores negativos en alguno de los límites inferiores del intervalo de confianza. Esto es porque la expresión matemática del intervalo de confianza permite este tipo de valores, pero al tratarse de una función de supervivencia $S(t)$ su rango serán valores en $[0,1]$, por lo que, por convención, se coloca el valor 0 cuando se tiene un número negativo.
[^8.2]: Tanto para estas bandas como las de Hall & Wellner se consideran los $D$ eventos distintos del tiempo $t_1<t_2<\cdots<t_D$; $t_L<t_U$ el rango de tiempo para las bandas de confianza, por lo que $t_U$ es menor o igual al evento de tiempo más grande. $t_L$, en este caso es más grande o igual al tiempo de evento más pequeño y para ambas bandas se tiene que $\alpha_L = \frac{n\sigma^2_S(t_L)}{1+n\sigma^2_S(t_L)} \mbox{ y } \alpha_U = \frac{n\sigma^2_S(t_U)}{1+n\sigma^2_S(t_U)}$.
Las bandas EP al $100(1-\alpha)\%$ están dadas por $$\hat{S}(t)-e_{\alpha}(\alpha_L, \alpha_U)\hat{S}(t)\sigma_S(t)\leq S(t)\leq\hat{S}(t)+e_{\alpha}(\alpha_L, \alpha_U)\hat{S}(t)\sigma_S(t)$$ para todos los $t_L\leq t\leq t_U$, donde $e_{\alpha}(\alpha_L, \alpha_U)$ es un cuantil tal que $\alpha = \mathbb{P}\left(\sup\limits_{\alpha_L\leq u\leq \alpha_U}\frac{|W^0(u)|}{[u(1-u)]^{1/2}}> e_{\alpha}\left(\alpha_L, \alpha_U\right)\right)$ donde $W^0(u)$ es un [puente browninano](https://en.wikipedia.org/wiki/Brownian_bridge) con $0\leq u\leq1$ y $\hat{S}(t)\sigma_S(t)$ se derivada del estimador de Greenwood.
[^8.3]: Las bandas Hall and Wellner al $100(1-\alpha)\%$ están dadas por $\hat{S}(t)-h_{\alpha}(\alpha_L, \alpha_U)\sqrt{n}\left[1+n\sigma^2_S(t)\right]\hat{S}(t)\leq S(t)\leq\hat{S}(t)+h_{\alpha}(\alpha_L, \alpha_U)\sqrt{n}\left[1+n\sigma^2_S(t)\right]\hat{S}(t)$ para todos los $t_L\leq t\leq t_U$ donde los valores críticos $h_\alpha(\alpha_L, \alpha_U)$ esta dado por $\alpha = \mathbb{P}\left(\sup\limits_{\alpha_L\leq u\leq \alpha_U}|W^0(u)|> h_\alpha\left(\alpha_L, \alpha_U\right)\right)$. En este caso, $t_L$ puede ser cero. Se puede consultar más sobre estas expresiones en el siguiente [enlace](https://documentation.sas.com/?cdcId=pgmsascdc&cdcVersion=9.4_3.4&docsetId=statug&docsetTarget=statug_lifetest_details11.htm&locale=ko).

<!--chapter:end:08_Nonparametric_estimates.Rmd-->

# Pruebas de Hipótesis

Las pruebas de hipótesis juegan un papel importante en la inferencia estadística. En el contexto del análisis de supervivencia, resulta primordial comparar poblaciones en cuanto a sus funciones de supervivencia, pues de ello podemos saber, por ejemplo, la *eficacia* de un tratamiento respecto a otro, los tiempos de aparición de un tumor en dos grupos, entre otras cosas.

El objetivo de la comparación de poblaciones en el análisis de supervivencia es similar a aquellos procedimientos diseñados para comparar estadísticos provenientes de muestras independientes, como la *prueba t*, la *prueba de los signos*, la *prueba U de Mann-Whitney*(1947), la *prueba de Kruskal-Wallis*(1952), etcétera. Todas estas pruebas de comparación se utilizan para evaluar diferencias entre estadísticos que han sido estimados basados en la información que se obtiene de subgrupos poblacionales independientes entre si. No obstante, dichas pruebas **no consideran la censura** en los datos, y por esta razón se imposibilita su aplicación "directa" en datos de supervivencia.

Las pruebas más utilizadas para comparar funciones de supervivencia, las cuales consideran la censura en los datos, son: la *prueba Log-Rank* propuesta por Mantel-Haenszel(1959), la *prueba generalizada de Wilcoxon* propuesta por Gehan(1965), la *prueba de Peto-Peto*(1972), la *prueba de Tarone-Ware*(1977), la *prueba de Harrington-Fleming*(1982) que generaliza parte de las pruebas anteriores y una versión más general propuesta por Fleming et al. (1987). En esta sección veremos la prueba de *Log-Rank* y la prueba generalizada de *Wilcoxon*, que esencialmente son la misma salvo una ponderación.

## Comparación de 1 población

Suponiendo que la tasa de riesgo real en la población estudiada es $h(t)$, el objetivo en esta prueba es determinar, estadisticamente, si la tasa de riesgo $h_0(t)$, la cual está completamente especificado en el intervalo $(0,\tau)$, es adecuada para las observaciones a tratar para un tiempo fijo $\tau$, es decir:

$$
\begin{array}{ccc}
H_0:h(t) = h_0(t)\ \forall \ t\leq \tau&vs& H_a:h(t) \neq h_0(t);\ \mbox{ p.a } \ t\leq \tau
\end{array}
$$

Recordando que el estimador de la función de riesgo acumulado es $\hat{H}_2(t) = \sum_{t_{i}\leq t}\frac{d_i}{n_i}$, entonces $\frac{d_i}{n_i}$ es un estimador de la tasa de riesgo en $t_i$.

Cuando la hipótesis nula es cierta, el valor esperado de la tasa de riesgo en $t_i$ es $h_0(t_i)$. Ahora, sea $\omega(t)$ la función de pesos tal que $\omega(t) = 0$ si $n_t = 0$, es decir que no se otorga algún peso cuando no hay elementos en dicho tiempo.

Considerando el clásico estadístico de prueba $Z(\tau) = O(\tau)-\mathbb{E}(\tau)$ (elementos observados menos esperados) [^9.1] y considerando que $D$ es el número de tiempos en la muestra, se tiene lo siguiente:

$$
Z(\tau) = O(\tau)-\mathbb{E}(\tau) = \sum_{i = 1}^D\omega(ti)\frac{d_i}{n_i}-\int_0^{\tau}\omega(s)h_0(s)ds
$$
Sólo para confirmar, $O(\tau)$ representa el número de eventos al tiempo $\tau$. Cuando $H_0$ es cierta

$$
Var(Z(\tau)) = \int_0^{\tau}\omega^2(s)\frac{h_0(s)}{n_s}ds
$$

Entonces, para muestras grandes el siguiente estadístico tiene una distribución $\chi^2_{(1)}$[^9.2].

$$
T = \frac{[Z(\tau)]^2}{Var(Z(\tau))}\sim\chi^2_{(1)}
$$

Cuando $\tau$ es igual al tiempo mayor en el estudio:

$$
\mathbb{E}[\tau] = Var(Z(\tau)) = \sum_{j = 1}^n\left(H_0(T_j)-H_0(L_j)\right)
$$

donde $H_0(t)$ es la función de riesgo acumulado bajo la hipótesis nula, $L_j$ es la edad de entrada y $T_j$ la edad de salida.

#### Ejemplo {-}

Se tiene una muestra de 26 pacientes con cierta enfermedad. Se desea probar que la tasa de riesgo es similar a la tasa de mortalidad de la población de Iowa en 1960. Realizando los cálculos correspondientes, se tiene lo siguiente

$$
Z(\tau) = O(26)-\mathbb{E}(26) = 15-4.4740\implies T=\frac{(15-4.4740)^2}{4.4740} = 24.76457
$$

El $p-value$ de $T = 24.76457$ (`r formatC(1-pchisq(24.76457, 1), format = "e", digits = 7)`) es cercano a cero $\implies$ se rechaza la hipótesis nula. $\therefore$ La tasa de riesgo NO es similar a la tasa de mortalidad de Iowa en 1960.

## Prueba Log-Rank

Mantel-Haenszel(1959) propusieron un estadístico que permite relacionar las pruebas de asociación de las tablas de contingencia con los contrastes de igualdad de funciones de supervivencia entre subgrupos poblacionales.

Suponga que se quiere contrastar las funciones de supervivencia de dos grupos poblacionales, digamos Grupo 1 y Grupo 2:

$$
\begin{array}{lllll}
H_{0}:S_{1}(t) = S_{2}(t) & \forall t>0 & vs & H_{a}:S_{1}(t) \neq S_{2}(t) & \mbox{p.a } t>0\\
\end{array}
$$

Suponga además que hay $k$ tiempos diferentes de **ocurrencia** del evento(fallas) en el grupo *combinado*, digamos: $t_{(1)},t_{(2)}, ... ,t_{(k)}$ y que en el momento $t_i$ ocurren $d_{1i}$ eventos en el primer grupo y $d_{2i}$ eventos en el segundo, para todo $i=1,2,...,k$. En cada momento $t_i$, hay $n_{1i}$ individuos en riesgo en el primer grupo y $n_{2i}$ individuos en el segundo.

En consecuencia, en el momento $t_i$ habrá $d_i=d_{1i}+d_{2i}$ (fallas totales) y $n_i=n_{1i}+n_{2i}$ (total de individuos en riesgo). La siguiente tabla muestra el número de ocurrencias del evento en el momento $t_i$, para el Grupo 1 y Grupo 2:

```{r}
data_frame(Grupo = c("I", "II", "Totales"), 
           "Fallos $t_{i}$" = c("$d_{1i}$", "$d_{2i}$", "$d_{i}$ "), 
           "Sobrevivientes $t_{i}$"=c("$n_{i1}-d_{1i}$", " $n_{2i}-d_{2i}$", "$n_{i}-d_{i}$"),
           "Individuos en riesgo $t_{i}$" = c("$n_{1i}$", "$n_{2i}$", "$n_{i}$")) %>% 
  kable(booktabs = T, align=rep('c'), escape = FALSE) %>% 
  kable_styling(bootstrap_options = "striped", full_width = F) %>% 
  row_spec(0, bold = F) %>% 
  column_spec(1:3, border_right = T) %>% 
  row_spec(3, bold = T)
```

Si se considera que en el momento $i$-ésimo se tiene una población formada por dos grupos, Grupo 1 y Grupo 2, y se define la variable aleatoria $d_{1i}$ como el número de eventos que ocurren en el Grupo 1 en el momento $t_i$. En ese momento se tiene una población de tamaño $n_i$ definida por el total de individuos en riesgo, clasificada en dos subpoblaciones de tamaños $n_{1i}$ (Grupo 1) y $n_{2i}$ (Grupo 2).

Si se asume que el número de fallas $d_i$ para los dos grupos combinados es una muestra aleatoria(sin reemplazo) de la población anterior, entonces la v.a. $d_{1i}$ sigue una distribución *hipergeométrica*($n_{i},d_{i},n_{1i}$) cuya media y varianza son:

$$
e_{1i} = \mathbb{E}(d_{1i}) = n_{1i} \frac{d_{i}}{n_{i}}
$$

$$
V_{1i}= Var(d_{1i}) = \frac{n_{1i}n_{2i}d_{i}(n_{i}-d_{i})}{n_{i}^2(n_{i}-1)}
$$

La hipótesis nula $H_0$ que se desea probar es que **no** hay diferencia entre las funciones de supervivencia de ambos grupos, lo que se logra evaluando la diferencia entre el número de fallas *observadas* y el número de fallas *esperadas* en cada uno de los momentos de ocurrencia, bajo los supuestos de $H_0$. Esto es equivalente a comparar el número de fallas ocurridas en cualquiera de los grupos con respecto al número de fallas esperadas en el grupo combinado.

De manera que, la prueba **Log-Rank** se basa en el estadístico:

$$
U_{L} = \sum_{i = 1}^{k}(d_{1i}-e_{1i})
$$

Entonces bajo $H_0$ (las supervivencias en las dos poblaciones son iguales) tenemos que : $\mathbb{E}(U_{L}) = 0$ y $Var(U_{L}) = \sum_{i=1}^{k}V_{1i}$. En consecuencia:

$$
L = \frac{U_L-\mathbb{E}(U_{L}) }{\sqrt{Var(U_{L})}}= \frac{\sum_{i = 1}^k(d_{1i}-e_{1i})}{\sqrt{\sum_{i=1}^{k}V_{1i}}} \sim N(0,1)
$$

$$
\Longrightarrow L^2= \frac{(\sum_{i = 1}^k(d_{1i}-e_{1i}))^2}{\sum_{i=1}^{k}V_{1i}} \sim \chi^2_{(1)}
$$

Finalmente, la **estadística** que ocuparemos para la prueba **Log-Rank** es:

$$
L^2= \frac{(\sum_{i = 1}^k(d_{1i}-e_{1i}))^2}{\sum_{i=1}^{k}V_{1i}}
$$

La **Regla de Decisión** es rechazar $H_0$ al nivel de significancia $\alpha$ si:

$$
L^2>J_{1-\alpha}
$$

Donde $J_{1-\alpha}$ es el cuantil $1-\alpha$ de una $\chi^2_{(1)}$. Recordemos que la regla de decisión puede obtenerse, también, a través del $p-value$.

La prueba Log-Rank es muy potente para detectar diferencias cuando los logaritmos de las funciones de supervivencia son *proporcionales*, no obstante, la potencia de la prueba disminuye cuando las funciones de supervivencia se **cruzan**.

#### Ejemplo {-}

Se tienen los tiempos de remisión (en semanas) para dos grupos de pacientes con leucemia. Cada grupo se conforma por 21 pacientes.

```{r}
data_frame("Grupo 1 (Tratamiento)" =c("6,  6, 6","7, 10, 13","16, 22, 23","6+, 9+, 10+","11+, 17+, 19+","20+, 25+, 32+","32+, 34+, 35+"), "Grupo 2 (Placebo)" = c("1, 1, 2","2, 3, 4","4, 5, 5","8, 8, 8","8, 11, 11","12, 12, 15","17, 22, 23")) %>% 
  kable( booktabs = T, align=rep('c')) %>% kable_styling(bootstrap_options = "striped", full_width = F)
```

La forma de la función de supervivencia para cada grupo es:

```{r}
tratamiento <- c(6,  6, 6,7, 10, 13,16, 22, 23,6, 9, 10,11, 17, 19,20, 25, 32,32, 34, 35)
placebo <- c(1, 1, 2,2, 3, 4,4, 5, 5,8, 8, 8,8, 11, 11,12, 12, 15,17, 22, 23)
cen_trat <- c(rep(1,9),rep(0,12))
cen_plac <- c(rep(1,21))
su_trat <- Surv(tratamiento, cen_trat)
su_plac <- Surv(placebo, cen_plac)
ajuste_trat <- survfit(su_trat~1,type="kaplan-meier",conf.type="plain")
ajuste_plac <- survfit(su_plac~1,type="kaplan-meier",conf.type="plain")

tibble(time_t = summary(ajuste_trat)$time, surv_t = summary(ajuste_trat)$surv) %>% 
  add_row(time_t = c(0, 35), surv_t = c(1, 0.4481793)) %>% 
  ggplot(aes(x = time_t, y = surv_t)) +
  geom_step(aes(color = "1"), key_glyph='rect') +
  geom_step(data = 
              (tibble(time_p = summary(ajuste_plac)$time, surv_p = summary(ajuste_plac)$surv) %>% 
              add_row(time_p = 0, surv_p = 1)), 
            aes(x = time_p, y = surv_p, color = "2"), key_glyph='rect') +
  guides(color = guide_legend(title=NULL))+
  general_theme+
  #Para simular el espacio entre las claves de las leyendas
  theme(legend.key = element_rect(colour = 'gray98', size = 2),
        legend.position = c(.9, .8), 
        legend.background = element_blank(),
        legend.text.align = 0,
        legend.direction = "vertical",
        legend.spacing.x = unit(.2, 'cm'),
        legend.key.size = unit(.4, "cm"))+
  scale_color_manual(values = c("1" = "deepskyblue4", "2" = "firebrick3"),
                     labels = c("Tratamiento", "Placebo")) +
  labs(x = "Tiempo", y = "Supervivencia estimada")+
  ggtitle("Funciones de Supervivencia. K-M")
```

Las funciones de supervivencia de los dos grupos "parecen" tener diferencia, de acuerdo a la gráfica anterior. No obstante, debemos comprobar si es una diferencia *significativa*. Enseguida corroboraremos tal afirmación mediante la prueba Log-Rank. 

La siguiente tabla muestra los individuos que fallan y los individuos en riesgo de cada grupo para cada tiempo $t_i$ ($i=1,2,...,k$), donde $k$=17. Además, se muestran los cálculos de las fallas esperadas para la construcción del estadístico Log-Rank:

```{r}
i=seq(1,17,1)
ti=c(1:8,10:13,15:17,22,23)
d1i=c(rep(0,5),3,1,0,1,0,0,1,0,1,0,1,1)
d2i=c(2,2,1,2,2,0,0,4,0,2,2,0,1,0,1,1,1)
n1i=c(rep(21,6),17,16,15,13,12,12,11,11,10,7,6)
n2i=c(21,19,17,16,14,rep(12,3),8,8,6,4,4,3,3,2,1)
e1i=n1i*((d1i+d2i)/(n1i+n2i))
e2i=n2i*((d1i+d2i)/(n1i+n2i))
d_o_1=d1i-e1i
d_o_2=d2i-e2i
V1i=(n1i*n2i*(d1i+d2i)*(n1i+n2i-(d1i+d2i)))/((n1i+n2i)*(n1i+n2i)*(n1i+n2i-1))

data_frame("$i$"=c(i,"","Total"),
           "$t_i$"=c(ti,"",""),
           "$d_{1i}$"=c(d1i,"",sum(d1i)),
           "$d_{2i}$"=c(d2i,"",sum(d2i)),
           "$n_{1i}$"=c(n1i,"",""),
           "$n_{2i}$"=c(n2i,"",""),
           "$e_{1i}$"=c(round(e1i,2),"",round(sum(e1i),2)),
           "$e_{2i}$"=c(round(e2i,2),"",round(sum(e2i),2)),
           "$d_{1i} - e_{1i}$"=c(round(d_o_1,2),"",round(sum(d_o_1),2)),
           "$d_{2i} - e_{2i}$"=c(round(d_o_2,2),"",round(sum(d_o_2),2)),
           "$V_{1i}$"=c(round(V1i,2),"",round(sum(V1i),2)))%>% 
  kable(booktabs = T, escape = FALSE, align=rep('c')) %>% kable_styling(bootstrap_options = "striped", full_width = F)
```

Entonces el estadístico **Log-Rank** es:

$$
L^2=\frac{(\sum_{i = 1}^k(d_{1i}-e_{1i}))^2}{\sum_{i=1}^{k}V_{1i}}=\frac{(-10.25)^2}{6.26}=16.78
$$

Para $\alpha=0.05$ tenemos que $J_{0.95}=3.8414$ por lo que:

$$
L^2=16.78>J_{0.95}=3.8414
$$

Por lo tanto, **se rechaza** $H_0$ y se concluye que **existe diferencia significativa** entre las funciones de supervivencia para el Grupo 1 (Tratamiento) y el Grupo 2 (Placebo).

## Prueba Generalizada Wilcoxon

Se considera la hipótesis a probar:

$$
\begin{array}{lllll}
H_{0}:S_{1}(t) = S_{2}(t) & \forall t>0 & vs & H_{a}:S_{1}(t) \neq S_{2}(t) & \mbox{p.a } t>0\\
\end{array}
$$

La prueba *generalizada de Wilcoxon* es una generalización de la prueba *Log-Rank*; Wilcoxon añade una **ponderación** a las fallas *observadas* menos las fallas *esperadas*. El estadístico en el que se basa la prueba de Wilcoxon es:

$$
U_{w} = \sum_{i = 1}^k n_{i}(d_{1i}-e_{1i})
$$

Bajo la hipótesis nula $H_0$ tenemos que $\mathbb{E}(U_{w}) = 0$ y $V_{w} = Var(U_{w}) = \sum_{i=1}^{k}n_{i}^2V_{1i}$. En consecuencia:

$$
W=\frac{U_w-\mathbb{E}(U_{w})}{\sqrt{V_{w}}}=\frac{\sum_{i = 1}^k n_{i}(d_{1i}-e_{1i})}{\sqrt{\sum_{i=1}^{k}n_{i}^2V_{1i}}} \sim N(0,1)
$$

$$
\Longrightarrow W^2= \frac{(\sum_{i = 1}^k n_{i}(d_{1i}-e_{1i}))^2}{\sum_{i=1}^{k}n_{i}^2V_{1i}} \sim \chi^2_{(1)}
$$

Entonces, la **estadística** que consideraremos para la prueba generalizada de **Wilcoxon** será:

$$
W^2= \frac{(\sum_{i = 1}^k n_{i}(d_{1i}-e_{1i}))^2}{\sum_{i=1}^{k}n_{i}^2V_{1i}}
$$

La **Regla de Decisión** es rechazar $H_0$ al nivel de significancia $\alpha$ si:

$$
W^2>J_{1-\alpha}
$$

Donde $J_{1-\alpha}$ es el cuantil $1-\alpha$ de una $\chi^2_{(1)}$.

#### Ejercicio {-}

Realice la prueba generalizada de Wilcoxon de acuerdo a los datos del ejemplo de la sección anterior.

## Comparación de $m$ Poblaciones
 
Si deseamos comparar las funciones de supervivencia de $m$ poblaciones planteamos la siguiente hipótesis:

$$
H_0:S_1(t) = S_2(t) = ... = S_m(t) \forall t \mbox{ vs } H_a:S_r(t)\neq S_s(t) \mbox{ p.a } r\neq s; r,s = 1,...,m
$$

Para realizar la prueba, denotemos $d_{i}$ el vector de fallas al tiempo $t_i$, $i=1,...,k$ con vector de medias $\mathbb{E}(d_i)$ y las entradas de la matriz de varianzas[^9.3] y covarianzas de la siguiente manera:

$$
Var(d_{ji}) = \frac{n_{1i}\cdot n_{2i}\cdot d_i(n_i-d_i)}{n_i^2(n_i-1)}
$$

$$
Cov(d_{ji},...,d_{hi}) = \frac{-n_{ji}\cdot n_{hi}\cdot d_i(n_i-d_i)}{n_i^2(n_i-1)} \mbox{ , } j \neq h
$$

Donde $j$ y $h$ denota el Grupo e $i$ es el tiempo. Ahora bien, sumando sobre los tiempos de falla $t_i$:

$$
\underline{D} = \sum_{i = 1}^k\{\underline{d}_i - \mathbb{E}(d_i)\}
$$

$$
\underline{V} = \sum_{i=1}^kVar(\underline{d}_i)
$$

**Mantel-Haenszel** propone probar la hipótesis de $m$ supervivencias iguales usando la forma cuadrática $O = D^{t}V^{-1}D$, donde $V^{-1}$ es la inversa generalizada de $V$ que bajo $H_0$ se distribuye $\chi^2_{(m-1)}$.

[^9.1]: Ver el parecido con el estadístico utilizado en pruebas de independencia.
[^9.2]: ¿Qué distribución de conteo tiene la misma varianza que su media?
[^9.3]: Se tiene $n_{1j}$ y $n_{2j}$ ya que se esta asumiendo que todas las poblaciones tienen una misma distribución, por lo que se esperaría que la varianza fuera la misma que para la población 1.

<!--chapter:end:09_Hypotesis_testing.Rmd-->

# (PART) Lleno de riesgos {-}

# Modelo de Riesgos Proporcionales

Cuando se desea comparar 2 o más grupos de tiempos-evento, si los grupos son "similares" entonces se les pueden aplicar los métodos no paramétricos vistos. Usualmente los individuos en los grupos tienen características adicionales que pueden afectar el resultado, por ejemplo, variables como: edad, género, nivel socioeconómico, consumo del alcohol, ritmo cardiaco, nivel de colesterol, etcétera.

Dichas variables pueden usarse como **covariables** (variables explicativas, factores de riesgo, variables independientes) en un modelo que explique la variable respuesta. Así, después de ajustar las covariables, la comparación de tiempos de supervivencia entre grupos deberá tener menos sesgo y ser más precisa que la simple comparación de tiempos de supervivencia.

Otro problema a resolver será predecir la distribución del tiempo de ocurrencia de cierto evento a partir de un conjunto de covariables.

Los datos estarán dados de la siguiente forma: $(t_i, \delta_i,x_i)$ con $i = 1,...n$, donde:

+ $i$: individuos. 
+ $t_i$: tiempo de falla o censura.
+ $\delta_i$: indicador de falla o censura.
+ $x_i$: conjunto de covariables.

Nota: 

+ $X_i =(X_{i1}, X_{i2}, ..., X_{ip})$; donde $p$= número de covariables.
+ $X_i$ puede depender del tiempo, es decir, $X_{ik}$ es una v.a que cambia en el tiempo (peso, colesterol, etc.).

Sea $h_i(t|X_i)$ la función de riesgo al tiempo $t$ del individuo $i$ dadas las covariables $X_i$ (vector de riesgo). El **modelo** propuesto por Cox (1972) es:

$$
h_i(t) = \varphi(X_i ;\theta)\cdot h_0(t)
$$
Donde:

+ $\theta=(\theta_1,..., \theta_p)$ es el vector de $p$ parámetros asociados a las covariables (coeficientes de regresión).
+ $\varphi(\cdot,\cdot)$ es la *función liga* de las covariables con el tiempo t.
+ $h_{0}(t)$ es la función de riesgo *base*.

La función $\varphi(\cdot,\cdot)$ debe satisfacer que $\varphi(0,\theta) =1$, esto para que, en ausencia de covariables, se tenga que $h_i(t) = h_0(t)$.

La forma más común de $\varphi(X_i, \theta)$ es $\varphi(X_i, \theta) = e^{X_i^{'} \theta}$ (Supone que $X_i$ no tiene intercepto), entonces:

$$
h_i(t) = e^{X_i^{'} \theta}\cdot h_0(t)
$$

Si aplicamos *logaritmo* tenemos que:

$$
\ln(h_i(t)) = X_i^{'}\theta + \ln(h_0(t))
$$

\begin{equation}
\Longrightarrow X_i^{'}\cdot\theta = ln \left({\frac{h_i(t)}{h_0(t)}}\right)
(\#eq:cox-covariables-linear)
\end{equation}

Es decir, el cociente de la función de riesgo del individuo $i$ con respecto al riesgo base será igual a una forma lineal de las covariables.

El nombre de riesgos proporcionales se deriva del cociente de las funciones de riesgo de dos individuos:

$$
\frac{h_i(t)}{h_j(t)} = \frac{e^{X_i^{'} \theta}\cdot h_0(t)}{e^{X_j^{'} \theta} \cdot h_0(t)} = e^{(X_i-X_j)' \theta}
$$

A la expresión anterior se le conoce como **riesgo relativo** y es constante en el tiempo, cuyo valor depende simplemente de la diferencia entre valores de las covariables de los dos individuos[^10.1].

Si $X_{1i} = 1$ y $X_{1j} = 0$, representan tratamiento y placebo respectivamente, y si todas las demás covariables se mantienen constantes, entonces $e^{\theta_1}$ es el riesgo de que se presente la falla con el tratamiento relativo a que se presente la falla con el placebo.

$$\frac{h_i(t)}{h_j(t)} = e^{\theta_1}$$ 
Bajo el modelo de riesgos proporcionales, las funciones de supervivencia y densidad del individuo $i$ son:
$$S_i(t)=\{S_0(t)\}^{exp(X_i'\theta)}$$
$$f_i(t)=e^{(X_i'\theta)}h_0(t)\{S_0(t)\}^{exp(X_i'\theta)}$$

donde $S_0(t)=exp\{-H_0(t)\}$ es la función de supervivencia base y $H_0(t)$ la función de riesgo acumulado base.
Una consecuencia del supuesto de proporcionalidad entre los riesgos de dos individuos $i,j$ con covariables $X_i,X_j$ es que las funciones de riesgo y supervivencia **no se intersectan**.

```{r}
survival_final_graph <- tibble(x = c(0,30)) %>% 
  ggplot(aes(x = x)) +
  stat_function(fun = ~1-pexp(.x,rate=.8), aes(color = "1")) + 
  stat_function(fun = ~1-pexp(.x,rate=.1), aes(color = "2"))+
  guides(color = guide_legend(title=NULL))+
  general_theme+
  #Para simular el espacio entre las claves de las leyendas
  theme(legend.key = element_rect(colour = 'gray98', size = 2),
        legend.position = c(.9, .4), 
        legend.background = element_blank(),
        legend.text.align = 0,
        legend.direction = "vertical",
        legend.spacing.x = unit(.2, 'cm'),
        legend.key.size = unit(.4, "cm"))+
  scale_color_manual(values = c("1" = "firebrick3", "2" = "deepskyblue4"),
                     labels = unname(TeX(c("$S_1(t)$", "$S_2(t)$")))) +
  labs(x = NULL, y = NULL)+
  ggtitle("Supervivencias")

risk_graph_final <- tibble(x = c(0,30)) %>% 
  ggplot(aes(x = x)) +
  stat_function(fun = ~log(.x), aes(color = "1")) + 
  stat_function(fun = ~log(.5*.x), aes(color = "2"))+
  guides(color = guide_legend(title=NULL))+
  general_theme+
  #Para simular el espacio entre las claves de las leyendas
  theme(legend.key = element_rect(colour = 'gray98', size = 2),
        legend.position = c(.9, .4), 
        legend.background = element_blank(),
        legend.text.align = 0,
        legend.direction = "vertical",
        legend.spacing.x = unit(.2, 'cm'),
        legend.key.size = unit(.4, "cm"))+
  scale_color_manual(values = c("1" = "firebrick3", "2" = "deepskyblue4"),
                     labels = unname(TeX(c("$h_1(t)$", "$h_2(t)$")))) +
  labs(x = NULL, y = NULL)+
  ggtitle("Riesgos")

survival_final_graph+risk_graph_final
```

**NOTA**: Si $S_0(t)$ es miembro de una familia paramétrica, por lo general, $S_i(t)$ no es miembro de la misma familia. Véase los siguientes ejemplos

+ Riesgo base Weibull: $h_0(t) = \lambda\alpha t^{\alpha-1}$
$$
\begin{array}{cc}
\implies h_i(t) = \lambda \alpha t^{\alpha-1}e^{X_i^{'}\theta} = \lambda e^{X_i^{'}\theta}\alpha t^{\alpha-1}&\therefore h_i\sim Weibull(\alpha, \lambda e^{X_i^{'}\theta})
\end{array}
$$
+ Riesgo base log-logistico: $h_0(t) = \frac{\alpha \lambda t^{\alpha-1}}{(1+\lambda t^{\alpha})}$
$$
\implies h_i(t) = \frac{e^{Xi^{'}\theta}\alpha t^{\alpha -1}}{(1+\lambda t^{\alpha})}
$$

+ Riesgo base Gamma: $S_0(t) = 1-lg(\lambda t, \beta)$
$$
S_i(t) = \{S_0(t)\}^{e^{X_i^{'}\theta}} = \left(1-lg(\lambda t, \beta)\right)^{e^{X_i^{'}\theta}}
$$

## Inferencia sobre $\theta$

La inferencia para los modelos de riesgos proporcionales paramétricos se hacen por máxima verosimiliutd.

Sea $(t_i, \delta_i, X_i)$

+ i : individuos.
+ $t_i$: tiempo de fallo o censura.
+ $\delta_i$: Indicador de fallo o censura.
+ $X_i$: Covariables.

Sean $h_0(t|\alpha, \lambda)$ y $S_0(t|\alpha, \lambda)$ funciones de riesgo y supervivencia base.

Entonces la función de verosimilitud para $(\theta, \alpha, \lambda)$ será: 

$$
\begin{split}
\mathscr{L}(\theta, \alpha, \lambda) & =\prod_{i = 1}^{n}\{f_i(t)\}^{\delta_{i}}\{S_i(t)\}^{1-\delta_{i}}\\
 & =\prod_{i = 1}^{n}\left\{e^{X_i^{'}\theta}h_0(t)S_0(t)^{e^{X_i^{'}\theta}}\right\}^{\delta_{i}}\left\{S_0(t)^{e^{X_i^{'}\theta}}\right\}^{1-\delta_i}\\
 & =\prod_{i = 1}^{n}\left\{e^{X_i^{'}\theta}h_0(t)\}^{\delta_{i}}\{S_0(t)^{e^{X_i^{'}\theta}}\right\}
\end{split}
$$ 

+ Los estimadores máximo verosímil se obtienen numéricamente.
+ La forma explicita de $\mathscr{L}(\theta, \alpha, \lambda)$ dependerá de la elección de $h_0$.
+ Inferencia para los parámetros más allá de la estimación puntual se basa en los resultados asintóticos.

## Estimación Semiparamétrica (Verosimilitud parcial).
El modelo de riesgos proporcionales semiparamétrico surge cuando la función de riesgo base $h_0(t)$ se considera como una parámetro desconocido, y en este caso es necesario hacer inferencia para $\theta$ y $h_0(t)$. El parámetro de interés más importante del modelo es $\theta$ y entonces $h_0(t)$ es considerado un parámetro de ruido.   

Supongamos que los datos consisten en el vector de observaciones $T = (T_1, ..., T_n)$ de la densidad $f(t|\theta,\eta)$ donde $\theta$ es el vector de parámetros de interés y $\eta$ es parámetro de ruido.

Sean $t_{(1)}<t_{(2)}<...<t_{(D)}$ los tiempos de fallo observados de manera exacta.

Sea $X_{(j)}$ la variable asociada al individuo con tiempo de fallo $t_{(j)}$.

Definimos $R(t_{(j)})$ como el conjunto de todos los individuos en riesgo justo antes de $t_{(j)}$.

Entonces la **verosimilitud parcial** para $\theta$ es 

$$
_p\mathscr{L}(\theta) = \prod_{j = 1}^{D}\frac{h_{j}(t_{(j)})}{\sum\limits_{i\in R(t_{(j)})}h_{i}(t_{(j)})} = \prod_{j = 1}^{D}\frac{\exp\left(X_{(j)}^{'}\theta\right)}{\sum\limits_{i\in R(t_{(j)})}\exp\left(X_{i}^{'}\theta\right)}
$$

OBS : 

+ $_p\mathscr{L}(\theta)$ no depende de $h_0(t)$
+ El numerador depende sólo de la información del individuo que falla.
+ El denominador usa información de todos los individuos que aún no han experimentado fallo incluyendo censurados.
+ La verosimilitud parcial se trata como cualquier función de verosimilitud (aplica logaritmo, derivada igual a cero,...)
+ $\theta$ es un vector de dimensión $p\implies$ se obtendrán $p$ derivadas parciales. La mayoría de los paquetes usan algoritmos de Newton-Raphson para resolver el sistema de ecuaciones simultaneas.
+ Pruebas de hipótesis e intervalos de confianza para $\theta$ se pueden obtener con distribución asintótica normal con media $\theta$ y matriz de varianzas y covarianzas.


## Estimador de Breslow ($H_{0}(t)$ y $S_{0}(t)$)

Si la funciones base son también de interés, se puede utilizar el estimador propuesto por Berslow (1974) que es una generalización del estimador de _Nelson-Aalen_.

$$\hat{H_{0}}(t) = \sum_{i:t_i\leq t}\left \{\frac{\delta_i}{\sum_{j = 1}^nY_j(t_i)e^{X_j^{'}\hat{\theta}}} \right \} = \frac{\mbox{Fallecidos}}{\mbox{Individuos en riesgo}}$$
donde $Y_i(t) = \mathbb{1}_{\{t_i\geq t\}}$ indicadora si $\hat{\theta} = 0$ y $\hat{H_0}(t)$ es el estimador de Nelson-Aalen visto previamente.

$$\therefore \hat{S_0(t)}  = exp\{-\hat{H_0}(t)\} = e^{\sum_{i:t_i\leq t}\left \{\frac{\delta_i}{\sum_{j = 1}^nY_j(t_i)e^{X_j^{'}\hat{\theta}}} \right \}}$$

**Notas**

1. En el caso de que se presenten **empates** (múltiples individuos con el mismo tiempo de fallo) la $_p\mathscr{L}(\theta)$ debe ajustarse para que se considere la naturaleza discreta de las observaciones.
2. El modelo de riesgos proporcionales permite la incorporación de covariables dependientes en el tiempo.

#### Ejemplo 1 {-}

Un estudio sobre la supervivencia clasifica según la raza en: blanco, negro e hispano. Entonces las variable $X_1$ toma los siguientes valores:

$$
\begin{array}{ll}
X_1 = \mbox{1 si es blanco } \\
X_1 = \mbox{2 si es negro } \\
X_1 = \mbox{3 si es hispano} \\
\end{array}
$$

Sin embrago, también podría plantearse como dos variables $X_1$ y $X_2$
$$
\begin{array}{ll}
X_1 = 1 \mbox{ si es blanco, 0 en otro caso.}\\
X_2 = 1 \mbox{ si es negro, 0 en otro caso}\\
\end{array}
$$

Entonces, el modelo de riesgos proporcionales será: $h(t|X) = h_0e^{\beta_1X_1+\beta_2X_2}$

+ Si $h(t|X_1=1, X_2 = 0) = h_0(t)e^{\beta_1}\longrightarrow$ Riesgo de blanco
+ Si $h(t|X_1=0, X_2 = 1) = h_0(t)e^{\beta_2}\longrightarrow$ Riesgo de negro
+ Si $h(t|X_1=0, X_2 = 0) = h_0(t)\longrightarrow$ Riesgo de hispano (riesgo base)

Riesgos relativos:

+ Entre negro e hispano: $\frac{h(t|X_1 = 0, X_2 = 1)}{h(t|X_1 = 0, X_2 = 0)} = \frac{h_0(t)e^{\beta_2}}{h_{0}(t)}=e^{\beta_2}$

Es decir, $e^{\beta_2}$ son las veces que el riesgo que tienen los negros en comparación con los hispanos.

+ Se busca que el riesgo relativo sea $\neq1$ para poder decir que la categoría segmenta datos.

#### Ejemplo 2 {-}

Un estudio con 863 pacientes con trasplante de hígado. Dos de las variable que se recabaron de los pacientes fueron, género y raza. Entonces los pacientes en el estudio se dividieron en las siguientes categorías 

$$
\begin{array}{ll}
432 \mbox{ hombres blancos}\\
92 \mbox{ hombres negros}\\
286 \mbox{ mujeres blancas}\\
59 \mbox{ mujeres negras}\\
\end{array}
$$

Para ajustar un modelo de riesgos proporcionales a estos datos, una opción es definir 3 covariables:

$$
\begin{array}{ll}
Z_1 = 1 \mbox{ hombre negro, 0.e.o.c}\\
Z_2 = 1 \mbox{ hombre blanco, 0.e.o.c}\\
Z_3 = 1 \mbox{ mujer negra, 0.e.o.c}\\
\end{array}
$$
Y el modelo para la función de riesgo será:
$$h(t|Z) = h_0(t)exp \{ \theta_1Z_1 + \theta_2Z_2 + \theta_3Z_3\}$$

Los estimadores máximo verosímil son $\hat{\theta_1} = 0.160$, $\hat{\theta_2} = 0.298$, $\hat{\theta_3} = 0.657$.

Riesgo relativo de hombre negro con mujer blanca : 

$$h(t|Z) = \frac{h_0(t)exp\{0.160\}}{h_0(t)exp\{0\}} = e^{0.160} = 1.17$$
$\therefore$ Los hombres negros son más propensos a morir por trasplante de hígado que las mujeres blancas; es decir, por cada mujer blanca, un hombre negro (1.17) muere en el trasplante.

En el caso de un hombre negro y un hombre blanco

$$h(t|Z) = \frac{h_0(t)exp\{0.160\}}{h_0(t)exp\{0.298\}} = e^{-0.088} = 0.9157609$$

Otra opción de plantear el modelo es con 2 covariables y una interacción, y quedaría de la siguiente forma:

$$
\begin{array}{ll}
Z_1 = 1 \mbox{ Si es mujer, 0  e.o.c}\\
Z_2 = 1 \mbox{ Si es negro(a), 0  e.o.c}\\
Z_3 = Z_1\cdot Z_2 \mbox{ Esta variable tomará el valor 1 si es mujer negra, y 0  e.o.c}
\end{array}
$$

Y el modelo para la función de riesgo será: $h(t|Z) = h_0exp\{\theta_1Z_1+\theta_2Z_2+\theta_3Z_1Z_2\}$.

Los estimadores máximo verosímil son 
$\hat{\theta_1} = -.2484, \hat{\theta_2} =-.0888, \hat{\theta_3} = .7435$.
Hay que notar que la interpretación de las $\theta's$ será diferente y en este caso el parámetro de interés será el de la interacción ($\theta_3$)

Riesgos relativos : 

$$\frac{\mbox{Hombre negro}}{\mbox{Mujer blanca}} = \frac{h_0(t)exp\{-0.0888\}}{h_0exp\{-0.2484\}} = e^{-(0.0888+0.2484)} = e^{-.1596} = 1.17$$

Véase que es el mismo resultado que se obtuvo en el modelo anterior, por lo que se sigue conservando el mismo riesgo independiente del modelo.

**Ejercicios**

1) Calcular el riesgo mujer negra relativo a mujer blanca.

2) Calcular el riesgo mujer negra relativo a hombre negro

3) Calcular el riesgo hombre blanco relativo a mujer blanca.

**RECORDATORIO: Codificación de variables categóricas**.

Una variable categórica con k clases se transforma en $k-1$ variables binarias.

#### Ejemplo 1 {-}

X: Color de cabello {negro, cafe, rojo, blanco}. Tenemos una variable con 4 categorías. Por lo que la transformaremos en 3 variables binarias

$$
\begin{array}{l}
X_1 = \mbox{1 si es negro, 0 e.o.c } \\
X_2 = \mbox{1 si es café. 0 e.o.c } \\
X_3 = \mbox{1 si es rojo, 0.e.o.c} \\
\end{array}
$$

Con estas tres variables se cubren todas las opciones de color de cabello.

## Significancia de los parámetros (Prueba de Wald)

¿Son significativos $\hat{\theta_1}, \hat{\theta_2}, \hat{\theta_3}$ en ejemplo numero 2?

Similar al caso de regresión lineal, la significancia de los parámetros radica en la importancia del riesgo proporcionado por las covariables asociadas a parámetros. Y en caso de no ser significativos los parámetros, las covariables se podrían eliminar del modelo.

**Prueba de hipótesis:** Nos interesa hacer pruebas sobre $\theta$, de manera general:

$$H_0:\theta_1 = \theta_{H_0}\mbox{ vs }H_1:\theta_1\neq \theta_{H_0}$$
donde $\theta = (\theta_1^t, \theta_2^t) = (\theta_1, \theta_2, ..., \theta_p)$

+ $\theta_1:$ Es el vector de $q*1$ ($q$ parámetros de interés)
+ $\theta_2:$ Los parámetros restantes ($p-q$)

Partimos la matriz de información : $I = \begin{pmatrix}I_{11} & I_{12} \\ I_{21} & I_{22}\end{pmatrix}$

Donde $I_{11}$, $I_{22}$ segundas derivadas de la función de verosimilitud.

La **Prueba de Wald** se define como:

$$
X_w^2 =(\hat{\theta_1}-\hat{\theta_{H_0}})^{'}[I^{*}(\theta)]^{-1}(\hat{\theta_1}-\hat{\theta_{H_0}})
$$

Donde $I^{*}(\theta)$ es la matriz $q*q$ superior de $I$.

+ Para muestras grandes, la estadística de prueba: $X_w^2\sim\chi_{(q)}^2$

* Un criterio de información es el proporcionado por el criterio de Aikaike ($ACI$):

$$AIC  = -2log{\mathscr{L}}+kp$$

+ $\mathscr{L}$: Función de verosimilitud.
+ $k$: Cte.(usualmente igual a 2).
+ $p$: # de parámetros en el modelo.  

Para la construcción del modelo usando el modelo de riesgos proporcionales de Cox, se puede usar el estadístico de Wald para seleccionar covariables significativas[^10.2] y considerando el valor del AIC para evaluar la mejora en el modelo[^10.3].

## Estimación de $S(t)$ después de obtener las estimaciones de los parámetros del modelo de Cox

Hasta el momento se han dado estimadores para $\theta$ y pruebas sobre dicho parámetro; es decir, teniendo el modelo de riesgos proporcionales $h(t|X) = h_0(t)e^{X^{'}\theta}$ y ajustando dicho modelo a nuestros datos obtenemos $\hat{\theta}$. Ahora lo que se desea es la función de supervivencia con el conjunto de covariables $X_i$.Para ello sea $t_1<t_2, \dots<t_D$ todos los tiempos de falla y $d_i$ el número de fallas del tiempo $t_i$. Entonces

$$
\omega(t_i, \hat{\theta}) = \sum_{j\in R(t_i)}\exp\left\{\sum_{h=1}^D\hat{\theta}_hX_{jh}\right\}
$$

Y el estimador de la función de riesgo acumulado base será la siguiente, la cual es una función escalonada a cada tiempo de falla.

$$
\hat{H_0}(t) = \sum_{t_i\leq t}\frac{d_i}{w(t_i, \hat{\theta})}
$$

Por lo que un estimador de la función de supervivencia base será el siguiente, el cual corresponde a los individuos cuyas covariables $X$ son ceros.

$$
\hat{S}_0(t) = \exp\{-\hat{H}_0(t)\}
$$

Para estimar la función de supervivencia para un individuo con covariables $X^{*}$ se utilizará el siguiente estimador

$$
\hat{S}(t|X^{*})=\hat{S}_0(t)\exp\left\{\hat{\theta^{'}}X^{*}\right\}
$$
La siguiente gráfica es un ejemplo comparativo de dos estimaciones de funciones de supervivencia, una con el método de Kaplan-Meier y Cox.

```{r}
#Por el momento la gráfica es creada con datos fijos sin usar las estimaciones correspondientes, ya que sólo es un ejemplo visual para las notas. Lo deseado sería la creación de dichas gráficas con las estimaciones reales.

tibble(xKM = c(0, 3, 6, 8, 9, 9.5,12, 16, 20), 
       yKM = c(1, .87, .8, .76, .7, .68,.6, .5, .5)) %>% 
  ggplot(aes(x = xKM, y = yKM, colour = "1")) +
  geom_step() + 
  geom_step(aes(x = xCox, y = yCox, colour = "2"), 
            data = tibble(xCox = c(0, 2.5, 6.5, 8.5, 9.3, 12.5, 16.3,20),
                          yCox = c(1, .83, .76, .68, .65, .58, .54, .54)))+
  lims(y = c(0,1.2)) + 
  general_theme + 
  scale_y_continuous(limits = c(0,1.15),
                     breaks = seq(0, 1, .25),
                     labels = seq(0, 1, .25))+
  scale_x_continuous(breaks = seq(0,20, 3), labels = seq(0,20, 3), 
                     expand = expand_scale(mult = c(0,0))) + 
  theme(axis.line = element_line(arrow =arrow(type = "closed", 
                                              length = unit(0.1, "inches")))) + 
  labs(x = "Tiempo", y = "Supervivencia estimada", colour = "Estimación: ") +
  scale_color_manual(values = c("deepskyblue3", "#752021"),
                     labels = unname(TeX(c("$\\hat{S}_{KM}$:", "$\\hat{S}_{cox}:$"))),
                     guide = guide_legend(label.position = "left",
                                          label.hjust = 0.5))
```


## Verificación de ajuste de Modelo 

Mediante gráficos de las funciones de supervivencia buscamos las funciones de supervivencia para los distintos valores de $X$'s donde **no** se crucen[^10.4].

En caso de que el modelo de Cox no cumpla con el supuesto de proporcionalidad se puede corregir el modelo mediante: 

  1) Agregar más covariables
  
  2) Considerar interacciones entre las covariables 
  
  3) Introducir términos no lineales
  
  4) Permitir que las covariables dependan del tiempo
  
## Extensión del modelo de Cox a covariables dependientes del tiempo 

Sea $X(t)=[X_1(t),...,X_p(t)]$ es el conjunto de covariables o factores de riesgo al tiempo $t$ que podrían afectar la distribución de la variable de supervivencia. 

Entonces $X_k(t)$´s son covariables dependientes del tiempo cuyos valores cambian o permanecen constantes (como el caso anterior). Supondremos que los valores de estas covariables son predecibles (el valor es conocido).

Ejemplos de este tipo de variables son presión arterial, colesterol, tamaño del tumor, etc. 

Sustituyendo en el modelo de Cox tenemos: 

$$
\begin{split}
h(t|X(t))=&h_0 (t)\cdot exp\{\beta^`\cdot Z(t )\}\\
=&h_0(t) \cdot exp \left\{ \sum_{k=1}^{p} \beta_k \cdot Z(t)  \right\}
\end{split}
$$

Entonces para probar el supuesto de riesgos proporcionales se crea una variable artificial:

$$
X_2(t)= X_1 \cdot g(t) 
$$

donde $X_1$ es una variable fija en el tiempo $g(t)$ es una función que depende del tiempo usualmente 

$$
g(t)= ln (t ) 
$$ 
y se ajusta un modelo de Cox para las covariables $X_1$ y $X_2(t)$, tenemos

$$  
\begin{split}
h(t|X(t)) &= h_0 \cdot exp \{ \beta_1 X_1 +\beta_2X_2(t) \}\\
&=h_0(t) \cdot exp \{ \beta_1 X_1+\beta_2 X_1\cdot g(t) \}
\end{split}
$$
y se realiza la prueba de hipótesis para $\beta_2=0$. Si se desea evaluar riesgos proporcionales para 2 individuos con diferentes valores de $X_1$ 

$$
\frac{h(t|X_1)}{h(t|X_1^*)}= exp \{ \beta_1 (X_1-X_1^*)+\beta_2\cdot g(t)(X_1-X_1^*) \}
$$

la cuál dependerá del tiempo si $\beta_2 \ne 0$.

[^10.1]: No hay dependencia con el tiempo.
[^10.2]: Recordar que por la ecuación \@ref(eq:cox-covariables-linear), el modelo esta asumiendo una forma lineal de las covariables.
[^10.3]: Para un mayor número de variables el $AIC\uparrow$ pero para variables más significativas $AIC\downarrow$.
[^10.4]: Por el hecho de que se busca **proporcionalidad** y, por lo tanto, que la segregación separe completamente a la población.

<!--chapter:end:10_Proportional_risks.Rmd-->

